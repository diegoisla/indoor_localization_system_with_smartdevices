{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analyst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = os.pardir\n",
    "\n",
    "RAW_DATA_PATH = ROOT_PATH + '\\\\data\\\\raw\\\\'\n",
    "\n",
    "PROC_DATA_PATH = ROOT_PATH + '\\\\data\\\\proc\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_id</th>\n",
       "      <th>WAP001</th>\n",
       "      <th>WAP002</th>\n",
       "      <th>WAP003</th>\n",
       "      <th>WAP004</th>\n",
       "      <th>WAP005</th>\n",
       "      <th>WAP006</th>\n",
       "      <th>WAP007</th>\n",
       "      <th>WAP008</th>\n",
       "      <th>WAP009</th>\n",
       "      <th>...</th>\n",
       "      <th>WAP123</th>\n",
       "      <th>WAP124</th>\n",
       "      <th>WAP125</th>\n",
       "      <th>WAP126</th>\n",
       "      <th>WAP127</th>\n",
       "      <th>MagneticFieldX</th>\n",
       "      <th>MagneticFieldY</th>\n",
       "      <th>MagneticFieldZ</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-15.4</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-33.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-15.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-33.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-15.4</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-33.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-15.4</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-33.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-33.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11444</th>\n",
       "      <td>324</td>\n",
       "      <td>-69</td>\n",
       "      <td>-69</td>\n",
       "      <td>-50</td>\n",
       "      <td>-49</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-75</td>\n",
       "      <td>-76</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-78</td>\n",
       "      <td>-77</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>14.1</td>\n",
       "      <td>-37.2</td>\n",
       "      <td>-19.6</td>\n",
       "      <td>32.4</td>\n",
       "      <td>34.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11446</th>\n",
       "      <td>324</td>\n",
       "      <td>-69</td>\n",
       "      <td>-69</td>\n",
       "      <td>-50</td>\n",
       "      <td>-49</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-75</td>\n",
       "      <td>-76</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-78</td>\n",
       "      <td>-77</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>14.1</td>\n",
       "      <td>-36.8</td>\n",
       "      <td>-19.6</td>\n",
       "      <td>32.4</td>\n",
       "      <td>34.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11447</th>\n",
       "      <td>324</td>\n",
       "      <td>-69</td>\n",
       "      <td>-69</td>\n",
       "      <td>-50</td>\n",
       "      <td>-49</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-75</td>\n",
       "      <td>-76</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-78</td>\n",
       "      <td>-77</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>14.1</td>\n",
       "      <td>-36.8</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>34.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11448</th>\n",
       "      <td>324</td>\n",
       "      <td>-69</td>\n",
       "      <td>-69</td>\n",
       "      <td>-50</td>\n",
       "      <td>-49</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-75</td>\n",
       "      <td>-76</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-78</td>\n",
       "      <td>-77</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>14.5</td>\n",
       "      <td>-36.8</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>34.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11455</th>\n",
       "      <td>324</td>\n",
       "      <td>-69</td>\n",
       "      <td>-69</td>\n",
       "      <td>-50</td>\n",
       "      <td>-49</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-75</td>\n",
       "      <td>-76</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>-78</td>\n",
       "      <td>-77</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>14.5</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>34.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5070 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       place_id  WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  \\\n",
       "3             2    -100    -100    -100    -100    -100    -100    -100   \n",
       "6             2    -100    -100    -100    -100    -100    -100    -100   \n",
       "7             2    -100    -100    -100    -100    -100    -100    -100   \n",
       "9             2    -100    -100    -100    -100    -100    -100    -100   \n",
       "14            2    -100    -100    -100    -100    -100    -100    -100   \n",
       "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "11444       324     -69     -69     -50     -49    -100    -100     -75   \n",
       "11446       324     -69     -69     -50     -49    -100    -100     -75   \n",
       "11447       324     -69     -69     -50     -49    -100    -100     -75   \n",
       "11448       324     -69     -69     -50     -49    -100    -100     -75   \n",
       "11455       324     -69     -69     -50     -49    -100    -100     -75   \n",
       "\n",
       "       WAP008  WAP009  ...  WAP123  WAP124  WAP125  WAP126  WAP127  \\\n",
       "3        -100    -100  ...    -100    -100    -100    -100    -100   \n",
       "6        -100    -100  ...    -100    -100    -100    -100    -100   \n",
       "7        -100    -100  ...    -100    -100    -100    -100    -100   \n",
       "9        -100    -100  ...    -100    -100    -100    -100    -100   \n",
       "14       -100    -100  ...    -100    -100    -100    -100    -100   \n",
       "...       ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "11444     -76    -100  ...    -100     -78     -77    -100    -100   \n",
       "11446     -76    -100  ...    -100     -78     -77    -100    -100   \n",
       "11447     -76    -100  ...    -100     -78     -77    -100    -100   \n",
       "11448     -76    -100  ...    -100     -78     -77    -100    -100   \n",
       "11455     -76    -100  ...    -100     -78     -77    -100    -100   \n",
       "\n",
       "       MagneticFieldX  MagneticFieldY  MagneticFieldZ     x     y  \n",
       "3               -15.4            -0.2           -33.3   1.2   0.6  \n",
       "6               -15.4            -0.8           -33.3   1.2   0.6  \n",
       "7               -15.4            -1.2           -33.3   1.2   0.6  \n",
       "9               -15.4            -1.2           -33.7   1.2   0.6  \n",
       "14              -15.0            -1.2           -33.7   1.2   0.6  \n",
       "...               ...             ...             ...   ...   ...  \n",
       "11444            14.1           -37.2           -19.6  32.4  34.2  \n",
       "11446            14.1           -36.8           -19.6  32.4  34.2  \n",
       "11447            14.1           -36.8           -20.0  32.4  34.2  \n",
       "11448            14.5           -36.8           -20.0  32.4  34.2  \n",
       "11455            14.5           -36.4           -20.0  32.4  34.2  \n",
       "\n",
       "[5070 rows x 133 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signals = pd.read_excel(PROC_DATA_PATH + 'measure1_wifi_smartphone.xlsx', index_col=0)\n",
    "signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = m1_wifi_df.iloc[:,:-2]\n",
    "# y = m1_wifi_df.iloc[:,-2:]\n",
    "\n",
    "X = signals.iloc[:,1:-2]\n",
    "y = signals.iloc[:,-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std = StandardScaler().fit(X)\n",
    "X = pd.DataFrame(std.transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle           \n",
    "\n",
    "X, y = shuffle(X, y, random_state=44)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models to evaluate: 12\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\src\\theBridge\\course-env\\lib\\site-packages\\sklearn\\svm\\_base.py:1201: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\src\\theBridge\\course-env\\lib\\site-packages\\sklearn\\svm\\_base.py:1201: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor,StackingRegressor,ExtraTreesRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Running multiple models with Pipeline\n",
    "models = []  # Empty list to store all the models\n",
    "\n",
    "# Appending pipelines for each model into the list\n",
    "models.append(\n",
    "    (\n",
    "        \"Linear Regression\",\n",
    "        Pipeline(\n",
    "            steps=[\n",
    "                (\"lin_reg\", LinearRegression(n_jobs=-1)),\n",
    "            ]\n",
    "        ),\n",
    "        {}\n",
    "    )\n",
    ")\n",
    "models.append(\n",
    "    (\n",
    "        \"KNeighbors\",\n",
    "        Pipeline(\n",
    "            steps=[\n",
    "                (\"knn\", KNeighborsRegressor(n_jobs=-1)),\n",
    "            ]\n",
    "        ),\n",
    "        {}\n",
    "    )\n",
    ")\n",
    "models.append(\n",
    "    (\n",
    "        \"Gradient Boosting wrapped\",\n",
    "        Pipeline(\n",
    "            steps=[\n",
    "                (\"gradient_boosting\", MultiOutputRegressor(\n",
    "                                                            LinearSVR())\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "        {}\n",
    "    )\n",
    ")\n",
    "models.append(\n",
    "    (\n",
    "        \"Extra Tree\",\n",
    "        Pipeline(\n",
    "            steps=[\n",
    "                (\"ExTree\", ExtraTreesRegressor()),\n",
    "            ]\n",
    "        ),\n",
    "        {}\n",
    "    )\n",
    ")\n",
    "\n",
    "models.append(\n",
    "    (\n",
    "        \"Decision Tree\",\n",
    "        Pipeline(\n",
    "            steps=[\n",
    "                (\"decision_tree\", DecisionTreeRegressor(random_state=42)),\n",
    "            ]\n",
    "        ),\n",
    "        {}\n",
    "    )\n",
    ")\n",
    "models.append(\n",
    "    (\n",
    "        \"Random Forest\",\n",
    "        Pipeline(\n",
    "            steps=[\n",
    "                (\"random_forest\", RandomForestRegressor(random_state=42,n_jobs=-1)),\n",
    "            ]\n",
    "        ),\n",
    "        {}\n",
    "    )\n",
    ")\n",
    "models.append(\n",
    "    (\n",
    "        \"Gradient Boosting wrapped\",\n",
    "        Pipeline(\n",
    "            steps=[\n",
    "                (\"gradient_boosting\", MultiOutputRegressor(\n",
    "                                                            GradientBoostingRegressor(random_state=42))\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "        {}\n",
    "    )\n",
    ")\n",
    "models.append(\n",
    "    (\n",
    "        \"XGB wrapped\",\n",
    "        Pipeline(\n",
    "            steps=[\n",
    "                (\"xgboost\", MultiOutputRegressor(\n",
    "                            XGBRegressor(random_state=42,eval_metric='logloss',n_jobs=-1))\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        {}\n",
    "    )\n",
    ")\n",
    "models.append(\n",
    "    (\n",
    "        \"Ridge\",\n",
    "        Pipeline(\n",
    "            steps=[\n",
    "                (\"Ridge\", Ridge(random_state=42)),\n",
    "            ]\n",
    "        ),\n",
    "        {}\n",
    "    )\n",
    ")\n",
    "models.append(\n",
    "    (\n",
    "        \"LASSO\",\n",
    "        Pipeline(\n",
    "            steps=[\n",
    "                (\"lasso\", Lasso(random_state=42)),\n",
    "            ]\n",
    "        ),\n",
    "        {}\n",
    "    )\n",
    ")\n",
    "models.append(\n",
    "    (\n",
    "        \"LGBM wrapped\",\n",
    "        Pipeline(\n",
    "            steps=[\n",
    "                (\"lgbm\", MultiOutputRegressor(\n",
    "                                                LGBMRegressor(random_state=42))\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "        {}\n",
    "    )\n",
    ")\n",
    "models.append(\n",
    "    (\n",
    "        \"CatBoost\",\n",
    "        Pipeline(\n",
    "            steps=[\n",
    "                (\"cat\", CatBoostRegressor(verbose=0,\n",
    "                                          loss_function='MultiRMSE', \n",
    "                                          eval_metric='MultiRMSE')),\n",
    "            ]\n",
    "        ),\n",
    "        {}\n",
    "    )\n",
    ")\n",
    "\n",
    "print('Number of models to evaluate:', len(models))\n",
    "\n",
    "# Declaro en un diccionario los pipelines e hiperparametros\n",
    "models_gridsearch = {}\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=44)\n",
    "\n",
    "for m in models:\n",
    "    models_gridsearch[m[0]] = GridSearchCV(m[1],\n",
    "                                          m[2],\n",
    "                                          cv=cv,\n",
    "                                          scoring=\"neg_mean_squared_error\",\n",
    "                                          verbose=1,\n",
    "                                          n_jobs=-1)\n",
    "    \n",
    "    models_gridsearch[m[0]].fit(X_train, y_train)      \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grid</th>\n",
       "      <th>Best score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extra Tree</td>\n",
       "      <td>-0.010199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>-0.038432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>-0.039871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>-0.047538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-0.072469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGB wrapped</td>\n",
       "      <td>-0.080796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LGBM wrapped</td>\n",
       "      <td>-0.094547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting wrapped</td>\n",
       "      <td>-1.328357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>-5.731186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>-5.741624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LASSO</td>\n",
       "      <td>-16.103125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Grid  Best score\n",
       "3                  Extra Tree   -0.010199\n",
       "4               Decision Tree   -0.038432\n",
       "1                  KNeighbors   -0.039871\n",
       "5               Random Forest   -0.047538\n",
       "10                   CatBoost   -0.072469\n",
       "6                 XGB wrapped   -0.080796\n",
       "9                LGBM wrapped   -0.094547\n",
       "2   Gradient Boosting wrapped   -1.328357\n",
       "7                       Ridge   -5.731186\n",
       "0           Linear Regression   -5.741624\n",
       "8                       LASSO  -16.103125"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_grids = [(i, j.best_score_) for i, j in models_gridsearch.items()]\n",
    "\n",
    "best_grids = pd.DataFrame(best_grids, columns=[\"Grid\", \"Best score\"]).sort_values(by=\"Best score\", ascending=False)\n",
    "best_grids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# define the model\n",
    "model_NN = Sequential()\n",
    "model_NN.add(Dense(1000, input_dim=130, kernel_initializer='he_uniform', activation='relu'))\n",
    "model_NN.add(Dense(300, activation='relu'))\n",
    "model_NN.add(Dense(2))\n",
    "model_NN.compile(loss='mse',\n",
    "              optimizer='adam',\n",
    "              metrics = ['mae','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "325/325 [==============================] - 4s 8ms/step - loss: 13.8661 - mae: 1.9423 - mse: 13.8661 - val_loss: 3.1858 - val_mae: 1.1168 - val_mse: 3.1858\n",
      "Epoch 2/100\n",
      "325/325 [==============================] - 2s 6ms/step - loss: 3.8987 - mae: 1.0951 - mse: 3.8987 - val_loss: 2.3889 - val_mae: 1.0576 - val_mse: 2.3889\n",
      "Epoch 3/100\n",
      "325/325 [==============================] - 2s 7ms/step - loss: 3.0281 - mae: 0.9166 - mse: 3.0281 - val_loss: 2.1159 - val_mae: 0.6783 - val_mse: 2.1159\n",
      "Epoch 4/100\n",
      "325/325 [==============================] - 2s 7ms/step - loss: 2.7508 - mae: 0.9371 - mse: 2.7508 - val_loss: 1.5689 - val_mae: 0.6427 - val_mse: 1.5689\n",
      "Epoch 5/100\n",
      "325/325 [==============================] - 2s 6ms/step - loss: 2.5723 - mae: 0.8832 - mse: 2.5723 - val_loss: 1.7483 - val_mae: 0.6864 - val_mse: 1.7483\n",
      "Epoch 6/100\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 1.9687 - mae: 0.6902 - mse: 1.9687 - val_loss: 1.1589 - val_mae: 0.5707 - val_mse: 1.1589\n",
      "Epoch 7/100\n",
      "325/325 [==============================] - 2s 7ms/step - loss: 2.0023 - mae: 0.7341 - mse: 2.0023 - val_loss: 1.2121 - val_mae: 0.5974 - val_mse: 1.2121\n",
      "Epoch 8/100\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 2.2944 - mae: 0.8543 - mse: 2.2944 - val_loss: 1.7590 - val_mae: 0.6500 - val_mse: 1.7590\n",
      "Epoch 9/100\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 1.7743 - mae: 0.6797 - mse: 1.7743 - val_loss: 2.2880 - val_mae: 0.8112 - val_mse: 2.2880\n",
      "Epoch 10/100\n",
      "325/325 [==============================] - 2s 7ms/step - loss: 1.8491 - mae: 0.7505 - mse: 1.8491 - val_loss: 1.2128 - val_mae: 0.6435 - val_mse: 1.2128\n",
      "Epoch 11/100\n",
      "325/325 [==============================] - 2s 6ms/step - loss: 1.4525 - mae: 0.6024 - mse: 1.4525 - val_loss: 1.7057 - val_mae: 0.7751 - val_mse: 1.7057\n",
      "Epoch 12/100\n",
      "325/325 [==============================] - 2s 5ms/step - loss: 1.6175 - mae: 0.6542 - mse: 1.6175 - val_loss: 1.3080 - val_mae: 0.5613 - val_mse: 1.3080\n",
      "Epoch 13/100\n",
      "325/325 [==============================] - 2s 5ms/step - loss: 1.7394 - mae: 0.7223 - mse: 1.7394 - val_loss: 1.0717 - val_mae: 0.5872 - val_mse: 1.0717\n",
      "Epoch 14/100\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 1.2743 - mae: 0.5613 - mse: 1.2743 - val_loss: 1.2595 - val_mae: 0.4488 - val_mse: 1.2595\n",
      "Epoch 15/100\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 1.8796 - mae: 0.6880 - mse: 1.8796 - val_loss: 3.0324 - val_mae: 0.9730 - val_mse: 3.0324\n",
      "Epoch 16/100\n",
      "325/325 [==============================] - 2s 5ms/step - loss: 1.6417 - mae: 0.6679 - mse: 1.6417 - val_loss: 0.8218 - val_mae: 0.3654 - val_mse: 0.8218\n",
      "Epoch 17/100\n",
      "325/325 [==============================] - 2s 5ms/step - loss: 1.3515 - mae: 0.5849 - mse: 1.3515 - val_loss: 1.8492 - val_mae: 0.9314 - val_mse: 1.8492\n",
      "Epoch 18/100\n",
      "325/325 [==============================] - 2s 7ms/step - loss: 1.3905 - mae: 0.6201 - mse: 1.3905 - val_loss: 0.8182 - val_mae: 0.4548 - val_mse: 0.8182\n",
      "Epoch 19/100\n",
      "325/325 [==============================] - 2s 6ms/step - loss: 1.2542 - mae: 0.5512 - mse: 1.2542 - val_loss: 1.1259 - val_mae: 0.4555 - val_mse: 1.1259\n",
      "Epoch 20/100\n",
      "325/325 [==============================] - 1s 5ms/step - loss: 1.5008 - mae: 0.6561 - mse: 1.5008 - val_loss: 1.0272 - val_mae: 0.4766 - val_mse: 1.0272\n",
      "Epoch 21/100\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 1.1390 - mae: 0.5308 - mse: 1.1390 - val_loss: 1.3315 - val_mae: 0.5945 - val_mse: 1.3315\n",
      "Epoch 22/100\n",
      "325/325 [==============================] - 1s 5ms/step - loss: 1.3129 - mae: 0.5893 - mse: 1.3129 - val_loss: 1.0788 - val_mae: 0.5521 - val_mse: 1.0788\n",
      "Epoch 23/100\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.9386 - mae: 0.4583 - mse: 0.9386 - val_loss: 1.0096 - val_mae: 0.4196 - val_mse: 1.0096\n",
      "Epoch 24/100\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.9910 - mae: 0.4498 - mse: 0.9910 - val_loss: 0.6898 - val_mae: 0.4700 - val_mse: 0.6898\n",
      "Epoch 25/100\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 1.0878 - mae: 0.5054 - mse: 1.0878 - val_loss: 0.7191 - val_mae: 0.4070 - val_mse: 0.7191\n",
      "Epoch 26/100\n",
      "325/325 [==============================] - 2s 6ms/step - loss: 1.2902 - mae: 0.5267 - mse: 1.2902 - val_loss: 2.0724 - val_mae: 0.7696 - val_mse: 2.0724\n",
      "Epoch 27/100\n",
      "325/325 [==============================] - 2s 6ms/step - loss: 1.0283 - mae: 0.4799 - mse: 1.0283 - val_loss: 0.8823 - val_mae: 0.5677 - val_mse: 0.8823\n",
      "Epoch 28/100\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.8493 - mae: 0.4266 - mse: 0.8493 - val_loss: 0.8107 - val_mae: 0.5094 - val_mse: 0.8107\n",
      "Epoch 29/100\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 1.1278 - mae: 0.5205 - mse: 1.1278 - val_loss: 0.7131 - val_mae: 0.3282 - val_mse: 0.7131\n",
      "Epoch 30/100\n",
      "325/325 [==============================] - 1s 5ms/step - loss: 1.0261 - mae: 0.4528 - mse: 1.0261 - val_loss: 0.8872 - val_mae: 0.4109 - val_mse: 0.8872\n",
      "Epoch 31/100\n",
      "325/325 [==============================] - 1s 5ms/step - loss: 0.9891 - mae: 0.4680 - mse: 0.9891 - val_loss: 0.8585 - val_mae: 0.4651 - val_mse: 0.8585\n",
      "Epoch 32/100\n",
      "325/325 [==============================] - 2s 5ms/step - loss: 1.0659 - mae: 0.4998 - mse: 1.0659 - val_loss: 1.0381 - val_mae: 0.6822 - val_mse: 1.0381\n",
      "Epoch 33/100\n",
      "325/325 [==============================] - 2s 6ms/step - loss: 0.7686 - mae: 0.3991 - mse: 0.7686 - val_loss: 1.1451 - val_mae: 0.5665 - val_mse: 1.1451\n",
      "Epoch 34/100\n",
      "325/325 [==============================] - 2s 5ms/step - loss: 1.3362 - mae: 0.5957 - mse: 1.3362 - val_loss: 0.5455 - val_mae: 0.3785 - val_mse: 0.5455\n",
      "Epoch 35/100\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.6538 - mae: 0.3587 - mse: 0.6538 - val_loss: 0.4812 - val_mae: 0.3321 - val_mse: 0.4812\n",
      "Epoch 36/100\n",
      "325/325 [==============================] - 2s 5ms/step - loss: 0.8812 - mae: 0.4318 - mse: 0.8812 - val_loss: 0.7052 - val_mae: 0.3974 - val_mse: 0.7052\n",
      "Epoch 37/100\n",
      "325/325 [==============================] - 2s 5ms/step - loss: 0.8980 - mae: 0.4522 - mse: 0.8980 - val_loss: 0.6524 - val_mae: 0.4272 - val_mse: 0.6524\n",
      "Epoch 38/100\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.6899 - mae: 0.3820 - mse: 0.6899 - val_loss: 0.5378 - val_mae: 0.2235 - val_mse: 0.5378\n",
      "Epoch 39/100\n",
      "325/325 [==============================] - 2s 6ms/step - loss: 0.9200 - mae: 0.4480 - mse: 0.9200 - val_loss: 0.5490 - val_mae: 0.3837 - val_mse: 0.5490\n",
      "Epoch 40/100\n",
      "325/325 [==============================] - 2s 5ms/step - loss: 0.9161 - mae: 0.4214 - mse: 0.9161 - val_loss: 1.9961 - val_mae: 0.7897 - val_mse: 1.9961\n",
      "Epoch 41/100\n",
      "325/325 [==============================] - 2s 5ms/step - loss: 0.9311 - mae: 0.4559 - mse: 0.9311 - val_loss: 0.5058 - val_mae: 0.2906 - val_mse: 0.5058\n",
      "Epoch 42/100\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.5991 - mae: 0.3383 - mse: 0.5991 - val_loss: 0.6870 - val_mae: 0.5513 - val_mse: 0.6870\n",
      "Epoch 43/100\n",
      "325/325 [==============================] - 2s 5ms/step - loss: 0.6000 - mae: 0.3528 - mse: 0.6000 - val_loss: 0.4385 - val_mae: 0.4187 - val_mse: 0.4385\n",
      "Epoch 44/100\n",
      "325/325 [==============================] - 2s 5ms/step - loss: 0.5781 - mae: 0.3309 - mse: 0.5781 - val_loss: 0.4186 - val_mae: 0.3576 - val_mse: 0.4186\n",
      "Epoch 45/100\n",
      "325/325 [==============================] - 2s 5ms/step - loss: 0.7576 - mae: 0.4268 - mse: 0.7576 - val_loss: 0.8720 - val_mae: 0.4938 - val_mse: 0.8720\n",
      "Epoch 46/100\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.7803 - mae: 0.4002 - mse: 0.7803 - val_loss: 1.0130 - val_mae: 0.4647 - val_mse: 1.0130\n",
      "Epoch 47/100\n",
      "325/325 [==============================] - 2s 5ms/step - loss: 0.9124 - mae: 0.4501 - mse: 0.9124 - val_loss: 0.5434 - val_mae: 0.4673 - val_mse: 0.5434\n",
      "Epoch 48/100\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.7177 - mae: 0.4073 - mse: 0.7177 - val_loss: 0.2579 - val_mae: 0.2583 - val_mse: 0.2579\n",
      "Epoch 49/100\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.6127 - mae: 0.3272 - mse: 0.6127 - val_loss: 0.5145 - val_mae: 0.3937 - val_mse: 0.5145\n",
      "Epoch 50/100\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 1.0491 - mae: 0.4802 - mse: 1.0491 - val_loss: 0.5632 - val_mae: 0.3365 - val_mse: 0.5632\n",
      "Epoch 51/100\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.6264 - mae: 0.3733 - mse: 0.6264 - val_loss: 0.4131 - val_mae: 0.3246 - val_mse: 0.4131\n",
      "Epoch 52/100\n",
      "325/325 [==============================] - 2s 5ms/step - loss: 0.5809 - mae: 0.3137 - mse: 0.5809 - val_loss: 0.3313 - val_mae: 0.2313 - val_mse: 0.3313\n",
      "Epoch 53/100\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.4978 - mae: 0.2786 - mse: 0.4978 - val_loss: 0.3035 - val_mae: 0.2911 - val_mse: 0.3035\n",
      "Epoch 54/100\n",
      "325/325 [==============================] - 2s 6ms/step - loss: 0.6576 - mae: 0.3825 - mse: 0.6576 - val_loss: 0.7303 - val_mae: 0.3381 - val_mse: 0.7303\n",
      "Epoch 55/100\n",
      "325/325 [==============================] - 2s 6ms/step - loss: 0.5524 - mae: 0.3288 - mse: 0.5524 - val_loss: 0.5887 - val_mae: 0.3908 - val_mse: 0.5887\n",
      "Epoch 56/100\n",
      "325/325 [==============================] - 2s 5ms/step - loss: 0.5639 - mae: 0.3354 - mse: 0.5639 - val_loss: 0.4327 - val_mae: 0.3957 - val_mse: 0.4327\n",
      "Epoch 57/100\n",
      "325/325 [==============================] - 1s 4ms/step - loss: 0.5821 - mae: 0.3569 - mse: 0.5821 - val_loss: 0.6995 - val_mae: 0.3628 - val_mse: 0.6995\n",
      "Epoch 58/100\n",
      "325/325 [==============================] - 2s 6ms/step - loss: 1.1865 - mae: 0.5037 - mse: 1.1865 - val_loss: 0.5706 - val_mae: 0.4679 - val_mse: 0.5706\n"
     ]
    }
   ],
   "source": [
    "history = model_NN.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 10,\n",
    "    epochs = 100,\n",
    "    validation_split = 0.2,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.866145</td>\n",
       "      <td>1.942257</td>\n",
       "      <td>13.866145</td>\n",
       "      <td>3.185843</td>\n",
       "      <td>1.116757</td>\n",
       "      <td>3.185843</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.898734</td>\n",
       "      <td>1.095088</td>\n",
       "      <td>3.898734</td>\n",
       "      <td>2.388912</td>\n",
       "      <td>1.057603</td>\n",
       "      <td>2.388912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.028092</td>\n",
       "      <td>0.916587</td>\n",
       "      <td>3.028092</td>\n",
       "      <td>2.115941</td>\n",
       "      <td>0.678300</td>\n",
       "      <td>2.115941</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.750753</td>\n",
       "      <td>0.937147</td>\n",
       "      <td>2.750753</td>\n",
       "      <td>1.568861</td>\n",
       "      <td>0.642749</td>\n",
       "      <td>1.568861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.572251</td>\n",
       "      <td>0.883196</td>\n",
       "      <td>2.572251</td>\n",
       "      <td>1.748312</td>\n",
       "      <td>0.686448</td>\n",
       "      <td>1.748312</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.968746</td>\n",
       "      <td>0.690231</td>\n",
       "      <td>1.968746</td>\n",
       "      <td>1.158897</td>\n",
       "      <td>0.570661</td>\n",
       "      <td>1.158897</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.002284</td>\n",
       "      <td>0.734104</td>\n",
       "      <td>2.002284</td>\n",
       "      <td>1.212116</td>\n",
       "      <td>0.597377</td>\n",
       "      <td>1.212116</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.294358</td>\n",
       "      <td>0.854344</td>\n",
       "      <td>2.294358</td>\n",
       "      <td>1.759014</td>\n",
       "      <td>0.650032</td>\n",
       "      <td>1.759014</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.774318</td>\n",
       "      <td>0.679743</td>\n",
       "      <td>1.774318</td>\n",
       "      <td>2.288014</td>\n",
       "      <td>0.811177</td>\n",
       "      <td>2.288014</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.849074</td>\n",
       "      <td>0.750532</td>\n",
       "      <td>1.849074</td>\n",
       "      <td>1.212826</td>\n",
       "      <td>0.643490</td>\n",
       "      <td>1.212826</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.452462</td>\n",
       "      <td>0.602428</td>\n",
       "      <td>1.452462</td>\n",
       "      <td>1.705714</td>\n",
       "      <td>0.775099</td>\n",
       "      <td>1.705714</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.617529</td>\n",
       "      <td>0.654186</td>\n",
       "      <td>1.617529</td>\n",
       "      <td>1.307975</td>\n",
       "      <td>0.561271</td>\n",
       "      <td>1.307975</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.739386</td>\n",
       "      <td>0.722264</td>\n",
       "      <td>1.739386</td>\n",
       "      <td>1.071658</td>\n",
       "      <td>0.587237</td>\n",
       "      <td>1.071658</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.274323</td>\n",
       "      <td>0.561281</td>\n",
       "      <td>1.274324</td>\n",
       "      <td>1.259484</td>\n",
       "      <td>0.448791</td>\n",
       "      <td>1.259484</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.879569</td>\n",
       "      <td>0.688035</td>\n",
       "      <td>1.879569</td>\n",
       "      <td>3.032418</td>\n",
       "      <td>0.973009</td>\n",
       "      <td>3.032418</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.641660</td>\n",
       "      <td>0.667917</td>\n",
       "      <td>1.641660</td>\n",
       "      <td>0.821824</td>\n",
       "      <td>0.365407</td>\n",
       "      <td>0.821824</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.351455</td>\n",
       "      <td>0.584884</td>\n",
       "      <td>1.351455</td>\n",
       "      <td>1.849192</td>\n",
       "      <td>0.931351</td>\n",
       "      <td>1.849192</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.390481</td>\n",
       "      <td>0.620136</td>\n",
       "      <td>1.390481</td>\n",
       "      <td>0.818241</td>\n",
       "      <td>0.454816</td>\n",
       "      <td>0.818241</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.254173</td>\n",
       "      <td>0.551233</td>\n",
       "      <td>1.254173</td>\n",
       "      <td>1.125925</td>\n",
       "      <td>0.455488</td>\n",
       "      <td>1.125925</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.500779</td>\n",
       "      <td>0.656137</td>\n",
       "      <td>1.500779</td>\n",
       "      <td>1.027176</td>\n",
       "      <td>0.476562</td>\n",
       "      <td>1.027176</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.139001</td>\n",
       "      <td>0.530805</td>\n",
       "      <td>1.139001</td>\n",
       "      <td>1.331517</td>\n",
       "      <td>0.594499</td>\n",
       "      <td>1.331517</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.312879</td>\n",
       "      <td>0.589255</td>\n",
       "      <td>1.312879</td>\n",
       "      <td>1.078769</td>\n",
       "      <td>0.552137</td>\n",
       "      <td>1.078769</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.938587</td>\n",
       "      <td>0.458293</td>\n",
       "      <td>0.938587</td>\n",
       "      <td>1.009585</td>\n",
       "      <td>0.419610</td>\n",
       "      <td>1.009585</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.991040</td>\n",
       "      <td>0.449828</td>\n",
       "      <td>0.991040</td>\n",
       "      <td>0.689757</td>\n",
       "      <td>0.469954</td>\n",
       "      <td>0.689757</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.087829</td>\n",
       "      <td>0.505431</td>\n",
       "      <td>1.087829</td>\n",
       "      <td>0.719077</td>\n",
       "      <td>0.407025</td>\n",
       "      <td>0.719077</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.290235</td>\n",
       "      <td>0.526668</td>\n",
       "      <td>1.290235</td>\n",
       "      <td>2.072413</td>\n",
       "      <td>0.769646</td>\n",
       "      <td>2.072413</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.028313</td>\n",
       "      <td>0.479934</td>\n",
       "      <td>1.028313</td>\n",
       "      <td>0.882273</td>\n",
       "      <td>0.567670</td>\n",
       "      <td>0.882273</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.849307</td>\n",
       "      <td>0.426564</td>\n",
       "      <td>0.849307</td>\n",
       "      <td>0.810653</td>\n",
       "      <td>0.509416</td>\n",
       "      <td>0.810653</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.127838</td>\n",
       "      <td>0.520497</td>\n",
       "      <td>1.127838</td>\n",
       "      <td>0.713114</td>\n",
       "      <td>0.328177</td>\n",
       "      <td>0.713114</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.026117</td>\n",
       "      <td>0.452786</td>\n",
       "      <td>1.026117</td>\n",
       "      <td>0.887198</td>\n",
       "      <td>0.410858</td>\n",
       "      <td>0.887198</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.989140</td>\n",
       "      <td>0.468049</td>\n",
       "      <td>0.989140</td>\n",
       "      <td>0.858456</td>\n",
       "      <td>0.465072</td>\n",
       "      <td>0.858455</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.065851</td>\n",
       "      <td>0.499848</td>\n",
       "      <td>1.065851</td>\n",
       "      <td>1.038103</td>\n",
       "      <td>0.682242</td>\n",
       "      <td>1.038103</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.768633</td>\n",
       "      <td>0.399137</td>\n",
       "      <td>0.768633</td>\n",
       "      <td>1.145088</td>\n",
       "      <td>0.566471</td>\n",
       "      <td>1.145088</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.336238</td>\n",
       "      <td>0.595728</td>\n",
       "      <td>1.336238</td>\n",
       "      <td>0.545464</td>\n",
       "      <td>0.378540</td>\n",
       "      <td>0.545464</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.653776</td>\n",
       "      <td>0.358732</td>\n",
       "      <td>0.653776</td>\n",
       "      <td>0.481229</td>\n",
       "      <td>0.332085</td>\n",
       "      <td>0.481229</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.881227</td>\n",
       "      <td>0.431847</td>\n",
       "      <td>0.881227</td>\n",
       "      <td>0.705221</td>\n",
       "      <td>0.397443</td>\n",
       "      <td>0.705221</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.898032</td>\n",
       "      <td>0.452171</td>\n",
       "      <td>0.898032</td>\n",
       "      <td>0.652438</td>\n",
       "      <td>0.427154</td>\n",
       "      <td>0.652438</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.689927</td>\n",
       "      <td>0.382029</td>\n",
       "      <td>0.689927</td>\n",
       "      <td>0.537756</td>\n",
       "      <td>0.223488</td>\n",
       "      <td>0.537756</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.920038</td>\n",
       "      <td>0.448033</td>\n",
       "      <td>0.920038</td>\n",
       "      <td>0.549000</td>\n",
       "      <td>0.383745</td>\n",
       "      <td>0.549000</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.916119</td>\n",
       "      <td>0.421436</td>\n",
       "      <td>0.916119</td>\n",
       "      <td>1.996085</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>1.996085</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.931129</td>\n",
       "      <td>0.455875</td>\n",
       "      <td>0.931129</td>\n",
       "      <td>0.505802</td>\n",
       "      <td>0.290605</td>\n",
       "      <td>0.505802</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.599137</td>\n",
       "      <td>0.338341</td>\n",
       "      <td>0.599137</td>\n",
       "      <td>0.687033</td>\n",
       "      <td>0.551323</td>\n",
       "      <td>0.687033</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.599989</td>\n",
       "      <td>0.352812</td>\n",
       "      <td>0.599989</td>\n",
       "      <td>0.438462</td>\n",
       "      <td>0.418653</td>\n",
       "      <td>0.438462</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.578137</td>\n",
       "      <td>0.330928</td>\n",
       "      <td>0.578137</td>\n",
       "      <td>0.418598</td>\n",
       "      <td>0.357583</td>\n",
       "      <td>0.418598</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.757637</td>\n",
       "      <td>0.426828</td>\n",
       "      <td>0.757637</td>\n",
       "      <td>0.871967</td>\n",
       "      <td>0.493802</td>\n",
       "      <td>0.871967</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.780319</td>\n",
       "      <td>0.400231</td>\n",
       "      <td>0.780319</td>\n",
       "      <td>1.012963</td>\n",
       "      <td>0.464676</td>\n",
       "      <td>1.012963</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.912374</td>\n",
       "      <td>0.450149</td>\n",
       "      <td>0.912374</td>\n",
       "      <td>0.543436</td>\n",
       "      <td>0.467282</td>\n",
       "      <td>0.543436</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.717655</td>\n",
       "      <td>0.407288</td>\n",
       "      <td>0.717655</td>\n",
       "      <td>0.257918</td>\n",
       "      <td>0.258321</td>\n",
       "      <td>0.257918</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.612719</td>\n",
       "      <td>0.327239</td>\n",
       "      <td>0.612719</td>\n",
       "      <td>0.514530</td>\n",
       "      <td>0.393710</td>\n",
       "      <td>0.514530</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.049120</td>\n",
       "      <td>0.480217</td>\n",
       "      <td>1.049120</td>\n",
       "      <td>0.563228</td>\n",
       "      <td>0.336524</td>\n",
       "      <td>0.563228</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.626366</td>\n",
       "      <td>0.373350</td>\n",
       "      <td>0.626366</td>\n",
       "      <td>0.413125</td>\n",
       "      <td>0.324554</td>\n",
       "      <td>0.413125</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.580870</td>\n",
       "      <td>0.313712</td>\n",
       "      <td>0.580870</td>\n",
       "      <td>0.331335</td>\n",
       "      <td>0.231309</td>\n",
       "      <td>0.331335</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.497840</td>\n",
       "      <td>0.278600</td>\n",
       "      <td>0.497840</td>\n",
       "      <td>0.303501</td>\n",
       "      <td>0.291068</td>\n",
       "      <td>0.303501</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.657585</td>\n",
       "      <td>0.382451</td>\n",
       "      <td>0.657585</td>\n",
       "      <td>0.730272</td>\n",
       "      <td>0.338121</td>\n",
       "      <td>0.730272</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.552423</td>\n",
       "      <td>0.328827</td>\n",
       "      <td>0.552423</td>\n",
       "      <td>0.588696</td>\n",
       "      <td>0.390784</td>\n",
       "      <td>0.588696</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.563859</td>\n",
       "      <td>0.335386</td>\n",
       "      <td>0.563859</td>\n",
       "      <td>0.432651</td>\n",
       "      <td>0.395694</td>\n",
       "      <td>0.432651</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.582122</td>\n",
       "      <td>0.356861</td>\n",
       "      <td>0.582122</td>\n",
       "      <td>0.699486</td>\n",
       "      <td>0.362834</td>\n",
       "      <td>0.699486</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.186501</td>\n",
       "      <td>0.503749</td>\n",
       "      <td>1.186501</td>\n",
       "      <td>0.570553</td>\n",
       "      <td>0.467853</td>\n",
       "      <td>0.570553</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss       mae        mse  val_loss   val_mae   val_mse  epoch\n",
       "0   13.866145  1.942257  13.866145  3.185843  1.116757  3.185843      0\n",
       "1    3.898734  1.095088   3.898734  2.388912  1.057603  2.388912      1\n",
       "2    3.028092  0.916587   3.028092  2.115941  0.678300  2.115941      2\n",
       "3    2.750753  0.937147   2.750753  1.568861  0.642749  1.568861      3\n",
       "4    2.572251  0.883196   2.572251  1.748312  0.686448  1.748312      4\n",
       "5    1.968746  0.690231   1.968746  1.158897  0.570661  1.158897      5\n",
       "6    2.002284  0.734104   2.002284  1.212116  0.597377  1.212116      6\n",
       "7    2.294358  0.854344   2.294358  1.759014  0.650032  1.759014      7\n",
       "8    1.774318  0.679743   1.774318  2.288014  0.811177  2.288014      8\n",
       "9    1.849074  0.750532   1.849074  1.212826  0.643490  1.212826      9\n",
       "10   1.452462  0.602428   1.452462  1.705714  0.775099  1.705714     10\n",
       "11   1.617529  0.654186   1.617529  1.307975  0.561271  1.307975     11\n",
       "12   1.739386  0.722264   1.739386  1.071658  0.587237  1.071658     12\n",
       "13   1.274323  0.561281   1.274324  1.259484  0.448791  1.259484     13\n",
       "14   1.879569  0.688035   1.879569  3.032418  0.973009  3.032418     14\n",
       "15   1.641660  0.667917   1.641660  0.821824  0.365407  0.821824     15\n",
       "16   1.351455  0.584884   1.351455  1.849192  0.931351  1.849192     16\n",
       "17   1.390481  0.620136   1.390481  0.818241  0.454816  0.818241     17\n",
       "18   1.254173  0.551233   1.254173  1.125925  0.455488  1.125925     18\n",
       "19   1.500779  0.656137   1.500779  1.027176  0.476562  1.027176     19\n",
       "20   1.139001  0.530805   1.139001  1.331517  0.594499  1.331517     20\n",
       "21   1.312879  0.589255   1.312879  1.078769  0.552137  1.078769     21\n",
       "22   0.938587  0.458293   0.938587  1.009585  0.419610  1.009585     22\n",
       "23   0.991040  0.449828   0.991040  0.689757  0.469954  0.689757     23\n",
       "24   1.087829  0.505431   1.087829  0.719077  0.407025  0.719077     24\n",
       "25   1.290235  0.526668   1.290235  2.072413  0.769646  2.072413     25\n",
       "26   1.028313  0.479934   1.028313  0.882273  0.567670  0.882273     26\n",
       "27   0.849307  0.426564   0.849307  0.810653  0.509416  0.810653     27\n",
       "28   1.127838  0.520497   1.127838  0.713114  0.328177  0.713114     28\n",
       "29   1.026117  0.452786   1.026117  0.887198  0.410858  0.887198     29\n",
       "30   0.989140  0.468049   0.989140  0.858456  0.465072  0.858455     30\n",
       "31   1.065851  0.499848   1.065851  1.038103  0.682242  1.038103     31\n",
       "32   0.768633  0.399137   0.768633  1.145088  0.566471  1.145088     32\n",
       "33   1.336238  0.595728   1.336238  0.545464  0.378540  0.545464     33\n",
       "34   0.653776  0.358732   0.653776  0.481229  0.332085  0.481229     34\n",
       "35   0.881227  0.431847   0.881227  0.705221  0.397443  0.705221     35\n",
       "36   0.898032  0.452171   0.898032  0.652438  0.427154  0.652438     36\n",
       "37   0.689927  0.382029   0.689927  0.537756  0.223488  0.537756     37\n",
       "38   0.920038  0.448033   0.920038  0.549000  0.383745  0.549000     38\n",
       "39   0.916119  0.421436   0.916119  1.996085  0.789720  1.996085     39\n",
       "40   0.931129  0.455875   0.931129  0.505802  0.290605  0.505802     40\n",
       "41   0.599137  0.338341   0.599137  0.687033  0.551323  0.687033     41\n",
       "42   0.599989  0.352812   0.599989  0.438462  0.418653  0.438462     42\n",
       "43   0.578137  0.330928   0.578137  0.418598  0.357583  0.418598     43\n",
       "44   0.757637  0.426828   0.757637  0.871967  0.493802  0.871967     44\n",
       "45   0.780319  0.400231   0.780319  1.012963  0.464676  1.012963     45\n",
       "46   0.912374  0.450149   0.912374  0.543436  0.467282  0.543436     46\n",
       "47   0.717655  0.407288   0.717655  0.257918  0.258321  0.257918     47\n",
       "48   0.612719  0.327239   0.612719  0.514530  0.393710  0.514530     48\n",
       "49   1.049120  0.480217   1.049120  0.563228  0.336524  0.563228     49\n",
       "50   0.626366  0.373350   0.626366  0.413125  0.324554  0.413125     50\n",
       "51   0.580870  0.313712   0.580870  0.331335  0.231309  0.331335     51\n",
       "52   0.497840  0.278600   0.497840  0.303501  0.291068  0.303501     52\n",
       "53   0.657585  0.382451   0.657585  0.730272  0.338121  0.730272     53\n",
       "54   0.552423  0.328827   0.552423  0.588696  0.390784  0.588696     54\n",
       "55   0.563859  0.335386   0.563859  0.432651  0.395694  0.432651     55\n",
       "56   0.582122  0.356861   0.582122  0.699486  0.362834  0.699486     56\n",
       "57   1.186501  0.503749   1.186501  0.570553  0.467853  0.570553     57"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist = pd.DataFrame(history.history)\n",
    "df_hist['epoch'] = history.epoch\n",
    "df_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22348769009113312"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist['val_mae'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    df_hist = pd.DataFrame(history.history)\n",
    "    df_hist['epoch'] = history.epoch\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.plot(df_hist['epoch'], df_hist['mae'], label=['Train Error'] )\n",
    "    plt.plot(df_hist['epoch'], df_hist['val_mae'], label=['Val Error'] )\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.plot(df_hist['epoch'], df_hist['mse'], label=['Train Error'] )\n",
    "    plt.plot(df_hist['epoch'], df_hist['val_mse'], label=['Val Error'] )\n",
    "    plt.ylim([0,20])\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEHCAYAAAC0pdErAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABTe0lEQVR4nO2dd3zU5f3A308ue5CQQYAkkLAJBAKEoaCAAqIi4AScuLW11bbWYn+2rtqqba11VKWKW7EqKLYuZA8ZYW+IEEgChAwSQnZyz++P5y65JJdJLovP+/W61933+a7ne7l8P9/PVlprBEEQBKE6bq09AUEQBKFtIgJCEARBcIoICEEQBMEpIiAEQRAEp4iAEARBEJwiAkIQBEFwirurDqyUigLeA8IBDczXWv+z2jYK+CdwBVAAzNVab7Wtuw14zLbpn7TW79Z3ztDQUB0dHd1s1yAIgtDR2bJlS6bWOszZOpcJCKAM+I3WeqtSKgDYopRaqrXe67DN5UBf22s08BowWikVDDwOJGCEyxal1BKt9em6ThgdHU1iYqIrrkUQBKFDopQ6Wts6l5mYtNYn7NqA1joP2AdEVNtsBvCeNmwAgpRS3YDLgKVa62ybUFgKTHXVXAVBEISatIgPQikVDQwDNlZbFQGkOCyn2sZqGxcEQRBaCJcLCKWUP/A58JDW+owLjn+PUipRKZWYkZHR3IcXBEE4b3GlDwKllAdGOHyotV7kZJM0IMphOdI2lgZMqDa+0tk5tNbzgfkACQkJUlhKENoIpaWlpKamUlRU1NpTEQBvb28iIyPx8PBo8D6ujGJSwFvAPq31C7VstgR4QCm1EOOkztVan1BKfQf8WSnV2bbdFOBRV81VEITmJzU1lYCAAKKjozG3A6G10FqTlZVFamoqMTExDd7PlRrEWOAWYJdSartt7PdADwCt9evA15gQ1yRMmOvttnXZSqmngc22/Z7SWme7cK6CIDQzRUVFIhzaCEopQkJCaKwZ3mUCQmu9Fqjzl6FNrfGf17JuAbDABVMTBKGFEOHQdmjK30IyqYGXlh1i1UFxcAuCIDgiAgKYv/owq0VACIIgVEEEBODv5c7ZorLWnoYgCM1IcnIyPj4+xMfHV4xFR0eza9cu4uPjiY+PJzg4mJiYGOLj45k0aVKDjrtkyRKeffbZRs3FYrFUnDM+Pr7R+9fHhAkTSE5OBmDixIn4+/s3S1UJl4a5thf8vd05WywCQhA6Gr1792b79u1VxuLi4irG5s6dy7Rp07juuuuqbFNWVoa7u/Pb4/Tp05k+fXqj5uHj41NjHtUpLy/HYrHUulzXfo6sWLGCCRMmNGp+tSECAqNB5ImAEASX8eRXe9h7vHnzZGO7d+LxqwY1ap+wMKc16QDzFB4fH8/atWuZM2cO/fr1409/+hMlJSWEhITw4YcfEh4ezjvvvENiYiKvvPIKc+fOpVOnTiQmJnLy5Emef/75GsKmLqKjo5k1axZLly7lkUceYd68eVWWtdb8+c9/RmvNlVdeyXPPPQeAv78/9957Lz/88AOvvvoqwcHBDRImjUUEBBDg7c7ZotLWnoYgCC5m8+bNda4vKSmpMM2cPn2aDRs2oJTizTff5Pnnn+fvf/97jX1OnDjB2rVr2b9/P9OnT3cqIAoLC6uYuh599FFmzZoFQEhICFu3bgVg3rx5FcvHjx9nzJgxbNmyhc6dOzNlyhS++OILZs6cSX5+PqNHj66Yz7hx45r0fdSHCAiMBpF+RrI9BcFVNPZJv7Ww37TBJPrNmjWLEydOUFJSUmuC2cyZM3FzcyM2Npb09HSn29RlYnI8p+Py5s2bmTBhQoXWc9NNN7F69WpmzpyJxWLh2muvbezlNRpxUiNOakEQDH5+fhWff/GLX/DAAw+wa9cu3njjjVpLhnh5eVV8NqldTT+ns2VneHt7u8SkVB0REBgntfggBEFwJDc3l4gIU0T63Xfr7VfW7IwaNYpVq1aRmZlJeXk5H3/8MePHj2/ROYiAAAK8TBRTU6S/IAgdkyeeeILrr7+eESNGEBoaek7Hsvsg7K958+bVu0+3bt149tlnmThxIkOHDmXEiBHMmDHjnObRWMQHgdEgtIb8knL8veQrEYTzhXfeeafi88qVK6usmzFjhtMb8ty5c5k7d26N/QHOnj3r9DzVQ1Ht2HMXalueM2cOc+bMqbFfbedpbkSDAPy9TPlb8UMIQsfBYrGQm5tbJXrofGDixIkcPny4UWW9a0MelzEaBMDZ4lLAu3UnIwhCsxAVFUVKSkr9G3YwVqxY0WzHEg0C44MAyBMNQhAEoQIREDhqECIgBEEQ7IiAgArHtPggBEEQKhEBQaWAkFwIQRCESkRAYGoxgWgQgtCRqK3cN0CvXr04cOBAle0feuihimJ4zoiOjiYzM9PpeFxcXEWOwy9/+ctmmb+duXPnVoTg3nTTTQQHB/PZZ5816zlqQ6KYAD8v8UEIQkfEWblvgNmzZ7Nw4UIef/xxAKxWK5999hnr1q1r0nlWrFhRZzJd9fLhdZUTd6R6/sSHH35YkYPREoiAADwsbnh7uImAEARX8c08OLmreY/ZNQ4ub1zjHXvhuzlz5jBr1qwKAbF69Wp69uxJz549mTlzJikpKRQVFfHggw9yzz33NGl61cuHf/XVV1WW4+PjefjhhykrK2PkyJG89tpreHl51SgBHhgYiKenZ5PmcK64TEAopRYA04BTWuvBTtb/FrjJYR4DgTCtdbZSKhnIA8qBMq11gqvmaSfA20PCXAWhg2Mv9x0XF4ebmxs7duxg6NChLFy4sCJjecGCBQQHB1NYWMjIkSO59tprCQkJqfO4EydOrCied9ttt/GrX/0KqFo+/KuvvqpYLioqom/fvixbtox+/fpx66238tprr/HQQw8BVUuAz549u9m/h4biSg3iHeAV4D1nK7XWfwX+CqCUugr4ldY622GTiVrrmgY/F2GvxyQIggto5JN+SzBnzhwWLlzIoEGD+OKLL3jyyScBeOmll1i8eDEAKSkpHDp0qF4BUZuJqbZS3gcOHCAmJoZ+/foBRqi8+uqrFQKi+n6thcsEhNZ6tVIquoGbzwE+dtVcGoK/NA0ShPOK2bNnM2XKFMaPH8+QIUMIDw9n5cqV/PDDD/z444/4+voyYcKEWst8N4SmlPJuzHauptWjmJRSvsBU4HOHYQ18r5TaopSq0wColLpHKZWolErMyMho8jz8RYMQhPOK3r17Exoayrx58yrMS7m5uXTu3BlfX1/279/Phg0bXHLu/v37k5ycTFJSEgDvv/9+i5fybgitLiCAq4B11cxL47TWw4HLgZ8rpS6ubWet9XytdYLWOqGufrP14e/lLj4IQTjPmDNnDvv37+eaa64BYOrUqZSVlTFw4EDmzZvHmDFjGnSciRMnVoS53nrrrfVu7+3tzdtvv831119f4Q+57777zulaXEFbiGKaTTXzktY6zfZ+Sim1GBgFrHblJPy9RYMQhPONhx56qMLuD6Y73DfffON02+qluOsbr14+vPrypZdeyrZt2xp8vNagVTUIpVQgMB740mHMTykVYP8MTAF2u3ou4qQWhI5FRyz3fdNNN7Fq1Sq8vVum6rQrw1w/BiYAoUqpVOBxwANAa/26bbOrge+11vkOu4YDi5VS9vl9pLX+1lXztGOc1KarnO3cgiCcI635/9QRy31/+OGHTd63KR0zXRnFVLMNUs1t3sGEwzqOHQaGumZWtePv5UGZVVNcZsXbw/XNwAWho+Pt7U1WVhYhISHy0NXKaK3JyspqtObRFnwQbQJ7ye+8ojIREILQDERGRpKamsq5RBcKzYe3tzeRkZGN2kcEhI0Ah3pMYQFerTwbQWj/eHh4EBMT09rTEM6BthDm2iaQnhCCIAhVEQFho8LEVCzZ1IIgCCACogLRIARBEKoiAsJGgPSlFgRBqIIICBv+0jRIEAShCiIgbDiGuQqCIAgiICrwcrfgaXETASEIgmBDBIQDpmCfRDEJgiCACIgq+Hu5SxSTIAiCDREQDkjTIEEQhEpEQDjg7y1NgwRBEOyIgHBAekIIgiBUIgLCAekqJwiCUIkICAfESS0IglCJCAgH/L3dyRMNQhAEARABUYUAL3dKyqwUl5W39lQEQRBaHREQDtjrMeUXi4AQBEEQAeGAv7cHICW/BUEQwIUCQim1QCl1Sim1u5b1E5RSuUqp7bbXHx3WTVVKHVBKJSml5rlqjtWxaxDSNEgQBMG1GsQ7wNR6tlmjtY63vZ4CUEpZgFeBy4FYYI5SKtaF86ygoieEaBCCIAiuExBa69VAdhN2HQUkaa0Pa61LgIXAjGadXC1ITwhBEIRKWtsHcYFSaodS6hul1CDbWASQ4rBNqm3MKUqpe5RSiUqpxIyMjHOajL90lRMEQaigNQXEVqCn1noo8DLwRVMOorWer7VO0FonhIWFndOEArykaZAgCIKdVhMQWuszWuuzts9fAx5KqVAgDYhy2DTSNuZyRIMQBEGopNUEhFKqq1JK2T6Pss0lC9gM9FVKxSilPIHZwJKWmJOPhwU3JU5qQRAEAHdXHVgp9TEwAQhVSqUCjwMeAFrr14HrgPuVUmVAITBba62BMqXUA8B3gAVYoLXe46p5Vpuz9IQQBEGw4TIBobWeU8/6V4BXaln3NfC1K+ZVHwHeHuKDEARBoPWjmNocRoOQRDlBEAQRENWQnhCCIAgGERDVCPCWnhCCIAggAqIG/l7SE0IQBAFEQNRANAhBEASDCIhqSJirIAiCQQRENfy9PCgoKafcqlt7KoIgCK2KCIhq+EvJb0EQBEAERA0CpGmQIAgCIAKiBlKwTxAEwSACohoVTYPExCQIwnmOCIhq2DUIyYUQBOF8RwRENQJEgxAEQQBEQNRAfBCCIAgGERDVEB+EIAiCQQRENfw8xQchCIIAIiBq4OZm6yonGoQgCOc5IiCcIE2DBEEQREA4RZoGCYIguFBAKKUWKKVOKaV217L+JqXUTqXULqXUeqXUUId1ybbx7UqpRFfNsTb8vdylL7UgCOc9rtQg3gGm1rH+CDBeax0HPA3Mr7Z+otY6Xmud4KL51UqAaBCCIAiuExBa69VAdh3r12utT9sWNwCRrppLYxEntSAIQtvxQdwJfOOwrIHvlVJblFL3tPRkpGmQIAgCuLf2BJRSEzECYpzD8DitdZpSqguwVCm136aRONv/HuAegB49ejTLnPyl7aggCELrahBKqSHAm8AMrXWWfVxrnWZ7PwUsBkbVdgyt9XytdYLWOiEsLKxZ5hXg5c7ZkjKs0lVOEITzmFYTEEqpHsAi4Bat9UGHcT+lVID9MzAFcBoJ5Sr8vd3RGgpKy1vytIIgCG0Kl5mYlFIfAxOAUKVUKvA44AGgtX4d+CMQAvxLKQVQZotYCgcW28bcgY+01t+6ap7O8PfyAEw9JnttJkEQhPMNl939tNZz6ll/F3CXk/HDwNCae7QclRVdSwHv1pyKIAhCq9FWopjaFBV9qcVRLQjCeYwICCdITwhBEAQREE6RnhCCIAgiIJxiFxDSE0IQhPMZERBOCPAWDUIQBEEEhBP8vMQHIQiCUKeAUEp1qmNd89S1aIN4WNzw9nATASEIwnlNfRrESvsHpdSyauu+aO7JtCX8vTzIK5KucoIgnL/UJyCUw+fgOtZ1OAK8pWmQIAjnN/UJCF3LZ2fL7ZPyMvj+D3D0xyrDUvJbEITznfpKbXRRSv0aoy3YP2Nbbp7Sqa1NaT7s/y/s/ATuXQ0BXQFpGiQIglCfBvFvIADwd/hsX37TtVNrIbwDYdYHUJwHn86FcuN38Je2o4IgnOfUqUForZ+sbZ1SamTzT6eVCB8E01+Gz++E7x+Dy58jwNud7PyS1p6ZIAhCq9GoPAilVKxS6mmlVBLwmovm1DrEXQej74eNr8POT4mLCORUXjEp2QWtPTNBEIRWoV4BoZSKVko9qpTaCbwP3A9MsvVu6FhMeRp6XAhLfsHEoFMA/PhTVj07CYIgdEzqS5T7EfgfxhR1rdZ6BJCntU5ugbm1PBYPuP4d8A6k5w/3Eu1XyrqfMlt7VoIgCK1CfRpEOsYpHU5l1FLHCG+tjYBwuOE9VG4KL/i+zfqfstC6Y1+yIAiCM+oUEFrrmUAcsAV4Qil1BOislBrVAnNrPXqMhuG3ElewkYy8IpJOnW3tGQmCILQ49fogtNa5Wuu3tdZTgDGYXtL/UEqluHx2rUlIHzzKCwniLOvFDyEIwnlIo6KYtNbpWuuXtdZjgXEumlPbIMjUIhwemMe6JPFDCIJw/lFnHoRSakk9+0+vZ/8FwDTglNZ6sJP1CvgncAVQAMzVWm+1rbsNeMy26Z+01u/WM5fmJTAKgAldivjb4SzKrRqLW4cuPyUIglCF+kptXACkAB8DG2l8gb53gFeA92pZfznQ1/YajcmtGK2UCgYeBxIwTvEtSqklWuvTjTx/07FpEMMC8zhzqIw9x3MZEhnUYqcXBEFobeozMXUFfg8MxjzpTwYytdartNar6ju41no1kF3HJjOA97RhAxCklOoGXAYs1Vpn24TCUmBq/ZfTjPh0Bk9/enua6a9LEj+EIAjnF/VFMZVrrb/VWt+GcVAnASuVUg800/kjMBqKnVTbWG3jLYdSEBiFb/5x+nbxZ73kQwiCcJ7RkExqL6XUNcAHwM+Bl4DFrp5YQ1FK3aOUSlRKJWZkZDTvwYOiIPcYY/uEsjk5m+Ky8uY9viAIQhumvkzq94AfgeHAk1rrkVrrp7XWac10/jQgymE50jZW23gNtNbztdYJWuuEsLBmrkAe1ANyUriwdwhFpVa2H8tp3uMLgiC0YerTIG7GOJAfBNYrpc7YXnlKqTPNcP4lwK3KMAbI1VqfAL4DpiilOiulOgNTbGMtS2AUFOUwOsITNwXrzvd8iNw0+GsfSN/T2jMRBKEFqK/cd6PyJKqjlPoYmACEKqVSMZFJHrZjvw58jQlxTcKEud5uW5etlHoa2Gw71FNa67qc3a4hyCgxgcUniIsIZH1SJr+e3K/Fp9FmyNgH+RlwcrcpkS4IQoemvjDXc0JrPaee9Rrj13C2bgGwwBXzajCBJtSVnBQu6B3Nm2sOk19chp+XS7+2tstZm4+n4DzXpAThPOGcNIQOT5BdQBxjbJ8QyqyaTcktr8i0GfJtAqLwPP4OBOE8QgREXfiFgcULco+R0DMYT4tblf4QhSXlfLDhKFe+tIZXVyS14kRbiHzTI6NBGkRpEZw54dr5CILgUs5TW0kDcXODwEjIScHH08KwHkGsS8ok/UwR7/2YzIcbj5FTUEpYgBd//e4A4Z28uW5EZGvP2nVUmJgaoEFseBXWvwy/PWy+R0EQ2h0iIOojqAfkHANgbJ9QXlh6kHHPLafMqpk8MJy7LurFsB5BzH17E48u2kn3IG8u7B3aypN2EY3RILKPQOFpY47y66DfhyB0cOTRrj6CoiDXJHVfEdeVHsG+3DS6JysfnsD8WxMYFROMh8WNf900gugQP+57fwtJp/JaedIuIr8RGoRdiJxNd918BEFwKSIg6iOwh7kxlhbSp0sAqx+ZyBPTB9EzxK/qZj4eLJg7Ek93C7e/s5nMs8WtNGEXcrYRTup8W2mSvJOum48gCC5FBER9BFWGutZHVLAvb96WQEZeMXe/l0hRaQcqzWG1OmgQWVBfG9YCm4AQDUIQ2i0iIOrDlixH7rEGbR4fFcSLs4axPSWHRxftcuHEWpiiHNDlENAdykugJL/u7fNtJibRIASh3SICoj5sjYMaokHYmTq4K7dfGMOX29M4W1zmoom1MGdtDuqw/ua9Lkd1WQkU59r2Ew1CENorIiDqI6AbuLlXRDI1lAn9w7Bq2Hq05XocuRR7BFPYAPNelx/CUXiIBiEI7RYREPVhcYdO3SsimRrK8J6dsbgpNh1pWtbxqbwidqbmNGlfl2D3PzREgyhw6J0hGoQgtFtEQDSEwB6NMjEB+Hu5M7h7pyaX5nhs8W5mz9/QdnpQ2COY7BpEQR2akT2CKaC7aBCC0I4RAdEQHJLlGsPI6GC2p+Q0OprpVF4Ry/afoqCknG1tpQdF/ilQFgjpY5br1CBs68IHGQ2ivognQRDaJCIgGkJQFOSdMM7XRjAqJpiSMis7U3Mbtd+irWmUW7XpQZHURlqd5meYjGjfYEDVLSDsGkT4ICgtgOIOmjgoCB0cERANITAK0HCmcY30RkYHA7C5EWYmrTX/2ZzCyOjOxEcFsbatCIizGeDXBdws4BNUj5M6E5RbpTlK/BCC0C4RAdEQHMp+N4bOfp70C/dnYyMc1YlHT3M4M58bEqIY1yeUHSk55BaWmpVWK+z7Cqyt4JfIP1VZU8k3pH4NwicYOnUzy+KHEIR2iQiIhlCRLNc4RzUYLWLr0dOUlVsbtP0nm1Pw87RwRVw3xvYJxaphw2HbzfjA/+CTm2HfkkbP45zJzwD/LuazT3Dd9ZgKMo0w8e9qlkWDEIR2iQiIhtApElCNjmQC44c4W1zGvhP12+Hzikr5384TXDW0O35e7gzr0RkfD0ulH+KgrS130g+Nnsc5obXNxBRmln1D6hYQ+VngGwoB4WZZNAhBaJeIgGgI7p4mYa4JkUyjYowfoiHhrv/deYLC0nJuGGk0Fk93N0b3CjZ+CK3h0FKzYdLylo0MKjkLZYUOAiK4fh+EXwh4B5mGS6JBdGxW/Bm+/m1rz0JwASIgGopD2e/G0C3Qh6hgHzYdqb+Hwn8SU+jbxZ9hUUEVY+P6hHI4I59ThxLh7EmIGgN5xyFjf90HK8mH00cbPV+n2JPk7CYm3+D6fRC+oaAU+IeLgOjoHPyu8uFF6FC4VEAopaYqpQ4opZKUUvOcrP+HUmq77XVQKZXjsK7cYV0rGN2rERjVJA0CYFR0CJuTT6PreOo/lJ7HtmM5zBoZhVKqYnxsH+MYTt9i+wou+7N5T1pW90m/+z3MH988Dm17kpyfXUCEQFkRlBTU3NZabhoF2R3aAeHt08SUmQRr/i45HA3hTFplrS6hQ+EyAaGUsgCvApcDscAcpVSs4zZa619preO11vHAy8Aih9WF9nVa6+mummeDCeph/hGacMMdFdOZ7PwSfso4W+s2n2xOwd1NcfWwiCrjA7oGEOrvie+xFdBtKESOgNB+8FMdAqK0CHYvMjfqU/saPd8a2Osw2W/6PsZs5lSLKMgGtNEgoP1qENs/hGVPQfbh1p5J26a0yNYvJR+Ka/99C+0TV2oQo4AkrfVhrXUJsBCYUcf2c4CPXTifcyMoCqxlJmGukYyKCQGoNdy1pMzKom1pTBoYToi/V5V1SikmxXgRXbgH3WeyGex9KRxdD6WFAKxPyuRYlsPT/KHvofiM+ZyW2Oj51qCGiclcj3MBYXOo+9m2CejaPjWIHJt57tiG1p1HW8cxNyhftIiOhisFRATgaLRPtY3VQCnVE4gBljsMeyulEpVSG5RSM2s7iVLqHtt2iRkZGc0w7VoIbHjjoOpEh/gSFuDF5loExLJ96WTnlzDL5pyuzoyA/ViwcizkIjPQ51Jj4jm6nl2pudyyYBNP/XdP5Q67PjUOZZ9gSN3c6PnWwG5ismsFvjYNwpmj2p5FXaFBdDW9JEqLzn0eLYndf5MiAqJOHAWEmJk6HG3FST0b+Exr7Wi/6am1TgBuBF5USvV2tqPWer7WOkFrnRAWFua6GTYxWQ6MFjAqOthpZVetNR9tOkbXTt5c3M/5/IcWbuK09mdZXqQZ6DkWLF6UH1rGbz/bQblVs/pQJvnFZVCUa5yGg6+FyARI3dLo+dYg/5SJSHL3NMsVGoQTAVGhQTj4IKD9mZnsf+djG1t3Hm2dXEcB0c7+xkK9uFJApAGOj8SRtjFnzKaaeUlrnWZ7PwysBIY1/xQbQaDt5tzAznLVGRUTzPHcIlJPV5qCrFbNY1/sZs2hTG67MBqLm6q5o9WK77GVbPEYztqfbBVUPX2h5wWc3vUN+0/mcee4GErKrKw+mGEyrcuLIe56iBxpop2KztQ5t9P5JXUXFHRMkgMHH0QDNQhoXzePkoJKoZh5oO6cj/Od3NTKz6JBdDhcKSA2A32VUjFKKU+MEKgRjaSUGgB0Bn50GOuslPKyfQ4FxgJ7XTjX+vH0NTe9JpiYoLIuk12LKCu38ptPd/DhxmPcO74X943v5XzHE9shP4Oc7hPYcDiLUltG9qku4wgtOMytse48evkAOvt68P3edGNe6hwDESOMBoGG41trnVdGXjGTXljF41/uqXWbijpMdnw6m3enPgjbmN0M1R6T5ezaw6CrzXtzmOk6KmdSze9BubWvhwChQbhMQGity4AHgO+AfcB/tNZ7lFJPKaUco5JmAwt11RjQgUCiUmoHsAJ4VmvdugICmlz2G6B/1wA6ebuz6Ug2xWXl/OzDrSzelsZvL+vPvKkDqoS2VuHQUkDReejlFeW/y8qt/Gm/qXP0SL/juFvcuHRgODv27UcfWW20B6Wg+3BzjFpucFprHl20i6z8EpbuS8dqrSWk07EOE5gmSt5BtfsgvIPA4mGW26MGYXdQD7radBMUR3Xt5KaZ/wu/MNEgOiDurjy41vpr4OtqY3+stvyEk/3WA3GunFuTCIqC9DqetOvA4qZIiA7mx8NZ3PVuImsOZfLEVbHMHRtT946HvoeIESQM7IubOsLapEy2HTvNkpNBPB8Uhn/KKhhzO1Niw+m0/d8oD6sREGCqrob2h1TnkUyfb03jh33pxj+SnM3OtFziHZL0KqhuYoLak+XsdZjs+IWap8v2qEGEDYCuQyBF/BC1cibNaKxWqwiIDkhbcVK3DwKjjM21oclT1XImRsUEczSrgHVJmfz1uiH1C4f8LEjbAn2nEOjrQVxkEEu2p/HC0oNcNqgrXv0nwU8rwFrOxf3CmOm+nuM+/SGsX+UxIhOMgKg25+M5hTy5ZA+jooN57ebhKAUr9jv5By8rNo5vm4npUHoeJWXW2usx2bOo7bhZzL5n25GAOJ0M7t5GKPYYY/4GjewFct6Qm2r8c/5d2peWKDQIERCNIainCS+t70mpJB8+vB5ev6iKkJgcG050iC+v3Dic6xOch7RW4adlgIa+kwAY1yeE5KwCvD0sPD1jMKrPJBNCenwb3meSGaJ+4rOSMVUztiMTzFP96eSKIatV88hnOynXmr9dP5QQfy/io4JYedBJmLA9B8IvlA2Hs5j8j9WMe245Rwq8KDvrpFdFQVZVDQJs2dTt6OaRc9SYTZSCqNHmb35yZwvPIQXWvWSezNsqRWdMvk1ghC0hUjSIjoYIiMYQbHMkr/kblJc636YwB96/xpiGTu2pUhKjd5g/K387kSviujXsfIe+N0/j3UwA1yUDjMP38ati6dLJG3pNBJQ5x65P0Sg+zB9ZtYNdRIJ5T6sMd/1g41HWJmXyf1cOpEeILwAT+3dhZ2oOmWeLq87BIUnu08RU/L3cGdCtE1sy3DiVfpyHP93BnuMO58vPrAyDtePftZ1pEEfNwwAYDQJa3g+x5W1Y+gc4srJlz9sY7DkQnSKMBpF/SkqTdDBEQDSG3hNh1D2waT68Mw3OHK+6/mwGvDvN3Iyvfcs47ra83bRzWctNWe++k8HN/JlG9OzMpt9fyjXDbSG3fiHQPd5oGrs+pazHWDLdQvh+r8PNuEssePhWOKqPZObzl6/3c3G/MG4c1aNis4n9u6A1JlS2+jUBRV7BfLv7BFfGdeO9O0Zx6fABhFry+d/OE1z50lr++t1+87RbmwbRnp4uc45CZ5uACOhqhEVLJ8zZ/UaJTfz9tAT2ENfASKNBlJcYjVboMIiAaAxuFrjir+bmf3KXMSEdXmnW5abB25ebIm9zFkLcdTDsZjj4bdVkooaSttXUUuo7ucpwl07eVbfrfalxomYl4TH0BkbHBPP9HgdzjsXdRDOlbqbcqnn40x14WBTPXzukSuTUoO6dCPX3YsWBagLCVj5hdZoiv6Sca4abZPjOoV3xtBax4eELuWpod15fdZjDqWmgy6v6IMBoEPkZjapjlXQqj3fXJzd4+2ajMMf4XOwaBBgt4tjGlns6tlrh+DZw84ADX7dd81wVAWELYmhPDwJCvYiAaApx18E9K8yT8nszYekfYcFU46S7ZVGFz4Dht4G2wrYPGn+OHR+b6J/el9S9XZ9LzbvFE2KnMyU2nEOnznLYsTBg5Aj0yV08uXgrW46e5qkZg+kaWFXQuLkpJvQPY/XBjKrd72wmpv/sKyIiyKcin8NuRgokjyeuisXXw8Jb39nCaatrEP5dzPeQ3/BSKE9+tZfHl+zhwMn6Gy01K/YIpqBK7Yqo0UZQnj7SMnPIOmRs+xf+wtT/2t6E309LcCbN/Eb9uzoIiDYqzIQmIQKiqYT1h7uXm5DSdf801Sxv+wp6Xli5TXCM8RNsfa9xVWAT34bEt2DE7ZVJabURORK8A6HvFPDpzORBJu/g+73pVbZR5SXsSlzDveN7MbNaxVg7E/t3IbewlB2pOZWDZzOweviy/HA+1wyPwM2e7e1Q0TXE34ufTezDgcO2G2h1H0SALReigaGuB07mseaQcYB/vjW1nq2bGXsORGcHDSJqtHlP2dQyc7Cbl4bOhuiLYMu7bdNZnZtmGmlZ3I2JCUSD6GCIgDgXPP3gmvnGpHTXMuMPqE7C7SbbtKENVQ5+B//7tbnhX/58/dtbPOD2b2DaiwBEBPkQFxHI93sqb8ZfZhqn+K09MvndZQNqPdS4vqFY3BQr9js86eef4qylM1ZN1VLkdiFgS5a7fWw0ff2Ng9vq48RJDQ1+ulyw9gjeHm6Mjglm8ba0BvfzbhbsRfocTUxdBoJXp5ZzVKclmvOF9IURc43QOryiZc7dGHJTjIMaRIPooIiAOFeUgv6XG23BGf2vME9XDXFWp22FT+ea5Kzr3jZPZg0hfBD4Vxb6mxIbzraUHE6dKWLZvnR+/c0pMi1hzAhNq9QAnBDo48GIHp1ZcaDyKVDnZ5Ba6s+wHkH0CvOv3Ni3UoMA8PawMGuQDwDfHCmremBbuY3SnON8uT2NgpJq6x3IPFvM4u1pXDs8ktvHxpCRV8yaJCfhtK4i55i5OTtqbm4Wo6m1VMJcaiJ0H2aCEwZeZYRxU4MdXMmZtMoaZd5BxswpGkSHQgSEq7F4GGf1oe+rFjarTvYR+OgGY7+/8T/g5V/7tvUwZVBXtIYXlh7k5x9tJbZbJ4L6XoBbA3pDTBgQxp7jZ0g/Y8pzF+ecJLXEn2uqm6WcVHQd2tnc+P+yKqOqELCZHxYu38yDC7fz5JLaq6Z8sOEoJWVW7hgXwyUDuhDk68HnW1rQzOSYA+FIjzGm+VJhjmvPX1posvUjbeHJ7l4QfyPs/7ptZaNrbaL4Am2/i4r2siIgOhIiIFqC4beaf6it7ztfX5ANH15nHJI3L6oscNdE+oX70zPEl4WbUwjv5M2CuSNx7zHKPB3X8w88sb8xFayyRTOVnUknWwUybUj3qhtWFOyrFBCqIItyD39S86z8e3WlQ/fb/dnkaH88izKYEhvOJ4kpVbQUO0Wl5Xyw4SiXDOhC7zB/PN3dmD60O9/vTSe3sJa8k+bGMQfCkajRgHZ94b4TO0wkWMSIyrERt5uxpgQ7uIqCLJNA2CmycswvTExMHQwREC1B52gTjbT1PSivZl45vh3em2EyZ+cshNC+53w6pRSzRkbRPdCbd28fRViAlzGRQK11mewM6BpA107erDx4irLSUnzKcgkI6U5nP8+qG1o8wCuwaj2mgkws/qFcEdeVN1b/RFpOIU99tZf7PthKrnsIV/Vy4+Ubh9Ev3J95n+8kt6DqTX/JjuNkni3hznGV5rprh0dSUmbl610njKN/+8eVDYyaG62r5kA4EpkAyuJ6P4T972NPcAQI6Q0xF8NW587q7/ac5NvdLaxd5NqqGgc6CAjRIDocIiBaioTbIe84JNmc1Xnp8OXPYf4Eo6rf8F5l1m4zcP/43qz53SVEh/qZgW5DTWXS6mam/CxY9nRFPodSiokDwlhzMJO1uw5hwUqv6Fr8K77BVSu62uow/W7qAErLrUx5YRUL1h1h7oXRRPWIwbc4Ey93C3+/Pp7MsyU86dAFT2vNgrVHGNA1gAt7Vzq5h0QG0qeLvzEz7f8ffHEfLJhSUTqkrNzKr/+znfmrfzrXr8wIu9IC5xqEpx90jXO9HyIt0dT8qq5FjphrNMCfltfY5Zn/7eP57/a7dl7Vsef2BDqYHqUeU4dDBERL0W+qecLa9G9Y+yK8PAJ2LIQLfg6/3Ar9pzbr6ZRSVRsQefhA+OBKE0lpkQnPfWmYKR2ytLLI7oT+XcgrLuPdpeZm2DemDgFRTYPAL5SeIX7cc3Ev3JTi1RuH88T0QbgFdK24ecRFBvLzCb1ZtDWNpbZw3HVJWRXNjxwT+JRSXDs8ksSjpynYsMAk4RVkw1uXwcndPPvNfhZtTePVFT+ZIoLnwmknIa6ORI02T/i1lVlpDtK2VDUv2Rlwlbn2as7q9DNFHMsu4EhmPmeLa3f+NzsVZTaqaRAFmY0L6RbaNCIgWgqLBwy7xZTF+OFxiB4LP9sIlz1j8hhagsgESNsGuz6DV0caodBjNIy829i+sw8DMLZPKB4WRUmuuXm7d6rFJ1K9omt+VkUW9cNT+rPlD5O5coit7lRAuBEQtmzkBy7py8BunXh00S5O55fw1trDhPp7MT2+e/WzcPWwCCJVBj7HVkLCHXDHt6DcKH1zKjvWfcOwHkHkFpay0olfo1HkJJt3xyQ5R3qMhrJC1xXuO5thtARnAsLdE4bdBAe+gTMnKoY3J5vvX2vYd6LuzoHNSm4KWLyqJkXaEyKdlYEX2iUiIFqS0fdC3A1w8+dw4ycQ2qdlzx85Ekry4PM7TSjnLV/ATZ/C2F+a9Xu+AMDfy52R0cGEYLvhOHaTc8QnuFJAaG3TIIx5SCmFp7vDz8u/q6nVU2japnq6u/H364eSW1jCfR9sYcWBDG4Z0xMvd0uN03QN9OY3YZvRgDX+ZugykEPTPielNIAPvZ7lk/GnCfbz5Msdx2vs2yic5UA40nOcKX+x4i+ueUq2m/8iE5yvH36bcVbvWVwxlJh8Gg+L0bh2p+U6388V5KYZ85JjtFdFspyYmToKIiBaEv8ucO2/oc+k1jl/n8kmAW/6K3DvalN8EMwTc+TIKjeeO8bGMCnK9s9fvXSGHd+QSh9EcZ4RANXrMNkJqHnziO3eiV9e0peNR7LxdHfj5jG1PLlby7ms5AfWlMex8bQ/OQUl3PHlSe7zfAbVNRbPz27ld1F7+WFvOnlF52D+yTlqrqm2EOOAcLj8OeNHWvmXpp+nNlITjSO8W7zz9SG9TUXh5LUVQ5uOZDMqJpiwAC92p7WgBnEmrTJJzk5DkuW2f9S02mRCqyAC4nzCL8RoDMNvMclfjgy62phOsoyzd1JsONP7uJsn5trKffh2hpKzpqlQgS2ZrTZh4u+83MZ9E3pzyYAu3D++NyH+Xs73TVqGb9FJFrtN4tPEFH65cDsnc4t49paJeNz+PwgfxIysBRSXlfPdnnN4es05Vrv2YCfhDmMqXP1X2PdV08/ljLQtEB5r+p/XRs+xcHQdWK2cKSpl/8kzjIwOZnD3TlXLrrua3LSqEUxQf8G+s6fgi/thxZ9dOzeh2RABIRhiZ5h3By2C/EwT215bv2zHZLl8m925Vg3CebkND4sbC+aO5FeT+znZycbWd8EvDJ9BV7JoWxqrD2bw5PTBDO/R2Tztj7ob77xkJgem8eX2c3g6PX20dv+DHaXgir8ZP8Hi+yDjQNPP54jVajLpnfkfHIkeZ0pqn9rD1qOnsWqMgIgI5NCpsxSVtoCDuLzMRORV1yD86tEg0neb931fmSAJoc0jAkIwBEaaKB2bHwIwFUxr0wjAQUBkOWgQIc63tdunG5sNnHfSOGaHzuGaUaZh05xRUdw42uFGPvAqsHhyb/A21iVlciqvCTcfq9U4Xjv3pKCkjHfXJ/PYF7vIdxYZ5OENN7xvIsMW3mjKg58rWUlQnFs1/8EZPcea9+R1JCafxuKmGNYjiEHdAym36pZxVJ89aZzR1TUIL3/w9K89T8Xez704tzLcW2jTuFRAKKWmKqUOKKWSlFLznKyfq5TKUEptt73uclh3m1LqkO11myvnKdiInQnpu0xPCzAmAf9aHNRQpaIr+TYBUZsG4eUPHn6Nd2Bu/9A4ZoffxsjoYL576GKenjG42jw6Q5/JxOcuB23lvztOOD9WXeSdgPISfjjhzYXPLufxJXv4YMMx7nhns/PaUYERcP27Jh9j0b01Eti+2nGcyS+s4mRuA4VVfQ5qO0FRxgyWvIZNydkM7t4JX093Bkd0AmD38RYQEBU5EJE119WVC5G+x2gZfmEmkk5o87hMQCilLMCrwOVALDBHKRXrZNNPtNbxttebtn2DgceB0cAo4HGlVD11r4Vzxm5m2mszM+Vn1h7BBFUrutbngwBbb+pGaBBWqylP0nNcRcRX/64BuFuc/GzjrsO9IJ1ZYUcbbWZKyS7gjSWmWup7+43J5rP7LuCfs+PZnJxdu5CIHguX/QUOfgPrXqwYLimz8uw3+zl06iyPfL6zao/w2kjbYp6+Q+swtVWcdxz66Hp2pmSTYOvPERHkQ5CvB3taIpLJnkVd3cQEtmzqOgRE1zjzIHLwW9PTWjhnss4WU1jiGtOiKzWIUUCS1vqw1roEWAjMaOC+lwFLtdbZWuvTwFKgeTPJhJoERkDUGGNm0roBJqZqGoS7j8k4rg3/ro3TIJLXmCY9IxqgQPabCp7+3OqfyI7UXI5k5jfoFCnZBcx8dR1JB4z54+nbruDftyaQEB3MjPgI/jErnk1HsrnznUTn/4Sj7oZeE2BbZZ2tz7emkpZTyJVDurH6YAYfbjxW/0QqKria4IEtR0/z6ookyq1OhEvPsajCbHqUp1Q0cFJKERcRyO6WcFSfcZJFbccvzLmTurzM+GvCB5keKmVFJjNeOGdeWnaIsc8tp9QFZfFdKSAigBSH5VTbWHWuVUrtVEp9ppSKauS+KKXuUUolKqUSMzJcVKPnfGLQ1caZmLbFhK02yMR02nkv6uo0VoPY+q5JIhx4Vf3bevrCgCvpn70cL1XaIC3ibHEZd72bSGm5lXkXmMihnr2q9suYER/B328YysYjWdz57uaaQkIp6HuZSTLMSaG03MqrK5IYGhXEy7OHcVHfUJ753z6S6xJYpYXmO49MoLisnGe/2c/1r6/nr98dqMg0r0K08UOMdttHQnSlYj2oeyAHTuade0Z5feSmmTwaZwmetWkQ2T9BebEREFGjILAH7G6kmam81PSC/9/DzeP36QBorfl+bzoJPTvj4UyzPkda20n9FRCttR6C0RLebewBtNbztdYJWuuEsLCw+ncQ6iZ2OqBg03yzXJeJyd0TPAMqNYjqneSq0xgNIj/LRLsMmW2cwQ0h7nrcinO5u+thvtx+vE7TTrlV8+DH20jKOMu/bhpBSOkJ0x3Nw7vGtlcPi+Rv1w/lx8NZ3PXe5pqRQjEXm/fkNSzemkbq6UIevLQPbm6K568bgodF8ZtPdzjXBgBO7ARrGSm+scx4ZR2vr/qJGxKi6BHsy+urfqp5HUE9ybJ0YZLPQUIdQoMHR3SitFxzMN3FbVqd5UDY8Q83UVZlxVXH7RFM4YOMUI27Fn5aUem7agiHVxqtcvO/4ZVRlZquCyi3atb/lNkw82ArsjM1lxO5RVxm6yTZ3LhSQKQBUQ7LkbaxCrTWWVpr+y/pTWBEQ/cVXESn7tDjgspw1/q0AnvBPlsdpjoJCDd5E8Vn694uZRMsustoMA0xL9npNQF8Q7jeeyNHMvPZmerkKdOW+f3ct/tZtv8UT0wfxLi+ofXmQFwzPJK/XTeU9T9l8eDCbVVv9l1iwScY6+HVvLIiiSGRgRVl07sF+vDUjMFsOXqa+asPOz12ua2C6+z/lZCVX8KCuQk8e+0Q7r64F9tTcticfLrK9lYN68sHMFzvq3KDHNzdPNG7PKM6N8W5eQkqNc7q/cfT95hikXYfS9z1NbLC62X3IlNB+I7vzHk+vQ0+mlXZR7wZWbwtjRv/vZEf9rXt6rTf7TmJn1sJlw6o53+vibhSQGwG+iqlYpRSnsBsYInjBkqpbg6L04F9ts/fAVOUUp1tzukptjGhJRh0tbk5Q90mJqgs2OdQh6lW6mo9ai2Hff+Ft6bAW5NNTsCkJ80TZ0OxeEDsTHpkrKKzpZgvqpuZdnwCz/di10ePMX/1YW67oCe3jLEJhdO1lPl24NoRkTx2ZSzf7Unnmf/tq1zh5gYxF1F0cAXHsvP55SV9qxQcnBHfnSviuvLC0gMVYahaa/Ycz+Vv3x1g9bL/clwHEx8by/cPXcwlA0xI8PUjIgnx8+SNVVUr1SZlnGVNaX8Cyk9D5sGK8R7BvgR4ubveD5FbjwYBNf/G6XtNC1V3m8YTPgjCBjY8mqmsGPb/FwZOM1WP714BU54xGsWro01Oyqe3wwfXmd/Qvy6ANy6uWiusEdhb9i5Ye6SeLVuX7/ac5M/B3xD09sUuyS1pYE/LxqO1LlNKPYC5sVuABVrrPUqpp4BErfUS4JdKqelAGZANzLXtm62UehojZACe0lo37S8tNJ7Y6fDNI4Cu28QElQX7GqpBAGx83ZhzrOXmKbKsCPYuMXbqoB6mF/ewm+t2eNdG3PWoxLf4RcQBXkj0I7ewlIFdO3GhdQuxq+7H6u5L7IFXuCuqJ/OmXW72KS81fcPrS5ID7hwXQ0p2AQvWHSEq2Ifbx5pKt+U9x+G790suDS/g0oFVvzOlFH+aGcemI6f51SfbmTigC9/sOkFyVgFXWjbwsMd6knvfyCs3DqsiWLw9LNx2YTQvLD3IwfQ8+oUHAKa8xkbrQLNR8hoI6w+Am5sitnunRpfcsJvMvD1q1sGqQWmR+VsHRjlfb2t9e/L4Mb5NDuaWC6JNVeH0Pcb34EjcdbD8aZv2Vs93n/QDFJ+BQdeYZYs7XPiA+a1++6gpg+4VYHt1MmbJwyvhyGoYNLP+63KgqLScNYcy6eTtzo+Hs9h34gwDu3Vq1DFagqRTZzmekcVU/28gaoJT8+i54lIfhNb6a611P611b631M7axP9qEA1rrR7XWg7TWQ7XWE7XW+x32XaC17mN7tcGGvB2YgK62hCxVv1/BN8S0Ui0tqH/b0P7g7m38G8uehBV/MjWN1r4IPkGmD/cvtpmihk0RDmCS/QKjmOW9iYTozqw9lMn33yym94r72VXeg7H5z3PCrSu/L/w77sU5Zp/cVJP4VV+ZDRt/mBbL5Nhwnvrv3oonzeXFxrn96z4nq9zk7QT7efLctXHsP5nH/NWHiQr2Zf5EK6/4zIeo0UTP+YfT/W4Z0xMfD0sV81RicjYFfj3QAd0heV2V7QdHBLLvxBnKGhDRkpZTyF++3seoZ37gmn+tr9e5XVpu5Y3/rQFAd6pZdReo0CBe+2o9T3y1l2X70o1DOfeYKSNSZbLXmvfdn9c7V3YvMkERvcZXHQ/qAbM/hIcPwi+2wD0r4bYlLB/+CiV4cHLvWqeHq4sff8qisLScp2cOxtvDjXfWJTf6GC3Bd3tOcq1lDV5lZ0zbABfQ2k5qoa0y/hFT5dVSj5LpE2zCYaF+DSIwAn53FB5Ng/9Lhz9kwh9PwxM5cPdyGHxN/eerDzc3GHwNfimreOeGXmy6M5xPOr2INTCKnePf5Mqxw7Hc8A5uhVmmLpC9ixzUa2KyY3FTvDR7GEMiAvnlwm1sPXaav2wqJ0sFE1u0vdb9Lh0Yzn9/MY7E/5vE+9d0ZcrOX6ECusLsj2p9+uvs58mskVF8uT2NE7mFAGxOPs2omBBUtK0uk4MfIi4ikOIyK0kZzv08Wmu2HM3m5x9u5eLnV/Dm2iMMjQpi74kzvLL8UJ3X/fLyJFZu2gbAM2vz2FstKa+wpJzff2cE5oCAIroEeLFwc4rp5Q2mH4kjwTGmSGR9ZqaSApNNHzvdmBHr4cefsrhv4W52WmM4vnsVqw42Lrpx6b50/DwtTB3clauHRfLF9jSy80sadYyWYOnu49zv9R10H25ridv8iIAQnNNrPEx+qv7tHLWG+nwQYG6EXv7m3eJhbujNjd0Buu5FeP8a3LwC8L1jCTdfmsAfpsXSbeAYmPy0Sdba8Fqlk7OBGgSAj6eFN28bSViAF7Pnb+BwZgHFkReiktfUGVkzOCKQzm4F8NENxs9z46f1CtY7x8Vg1fD2umTScgpJyyk04a09xxpbf1alj6Iio9qJmSm/uIxZb2zg2td+ZM2hDO66KIbVj0zk/Tl9uTnOn3+t/KlWB/eWo6d5ZfkhrupptIzN2T5Me3kNjy7aRebZYg6m5zH9lbV8vC2dQvdOzBroyQ0JUaw8cIqcI0ao0MVJnmzc9SbC6dS+muvsHPoeSvNh0DWknymqs97UrtRc7n4vkZ7BvvQeNoHB6gj3v/sjXzWwFLzWmmX70hnfPwwvdwu3j42muMzKx5ua3xF+LpzILST4xCoirMeN9lBbvbRzRASEcG74OiS416dBtBThgyFsAKx/GaxlcMtiU6LCkdH3Qv8rTdOkfV+ZMtu1OV5rISzAi7fnjsLb3c308o6fYrSpugr4lZfCf241tZdmfQBh9WdORwX7Mm1INz7aeIzl+422NjI62BTuA+OHsBET6o+Ph8Xpjf6FpQfZlJzNH6bFsuH3l/LoZf2IOPAevBjHE4XP0NnPk99+trOGqelscRm/+mQ73YN8uNbWwuS9h65m7oUxfJqYwsS/rmT6K2s5XVDCe3eMwqdzd9zyTzFrZBRWDUf3bTbRR85Kcwy6GpRb3VrE7s/BrwsnOo9g/F9XMOmFVXy960SNENSkU2e57e1NBPp48P6do+ncbyyelDIzPItfLtzG+xuO1vtd7047Q/qZYi61BQr0Cw9gXJ9Q3vsx2SWJaE1l6d507rR8Q6lft8oKCC5ABIRwblTRIOrxQbQUSkHCneAdBDd/VuHErbHNjFeMzfzQ98b81QTzVp8u/iz99Xg+uGs0bg75EE7RGv73GziyCq56qTJ/ogHcc3EvzhaX8fy3+/H3cmdA1wAI6WPmf7TSD2GxOaqrl/7ekZLD2+uOcNPoHtw5Lgbf0wdNtM83j4DFE/e0RJ6d1ot9J87w2sqqUVNPfbWH1NMF/GNWPF75x8E3lMDATvzxqli+fehixvQOYWzvUL5+8CIu6htmq8d0iqhgXy7qGwrpe9Dhsc6fcv27QK+JkLjA+IKqU5xn/j6DZjJ/7VFKyzW+nhZ+9uFWZs3fUCEI03IKueWtjbgpxYd3jaZroHeFU/zJEflc0r8Lf/hiNy8vO1RnbsPSfem4KZg4oDLQ4Pax0aSfKebrXU2o8eUi9m9bx1jLHjwuuK9BZremIgJCODfs2dTQdjQIgNH3wG+T6i6f7RsM171ltIdGmJeqE97J2ySsdY42GcJHVjnf8NBSkx0+7lemfWgjGNQ9kIv6hpJXVMawHkGmHpVSxsyUvK5aPkQn9hw/g9WWq1FabmXeol2E+nvxu8kxsPwZEwKafRiu+TfMfA10OZcGHmdGfHdeXn6oIhz3290n+E9iKj+b0MdoLWfSquRA9Oniz79vTeCtuSPpEmDzo/hVFuybnRBFjPUoaV69ar+4y58z5rbP7qjZ7/vAt1BWxOmYaXy86RhXD4vg619exDNXDybp1FmuemUtj3y2g1ve3MjZ4jLeu2MU0aG2AIdO3aFTJB7HE3n9lhFcPSyCvy89yFt1hK7+sDedhJ7BBPt5VoxN7N+F6BBf3m4jzuqcghJGnFhIiZt34/KEmoAICOHcsGsNbh4mvLAt0ZAnqx5jYNb7MPH/zv18ShmtIHltjequlJfC9/9nnvqbeK77xvcGYFS0g1COHmt6M5yuvOkNigikoKScI1mmvMdba4+w78QZ/nx5JJ3enQSrnzcBAQ9shiE3VIafHtvAE1cNIsjXg99+toO0nELmLdrFkMhAHpzU12yTm1Z7iKsd//CKRLnJESV0UoWsPF1HlYPQvjD9JUjZCD88UXXd7s8hoDtvHAmjuMzKzyb0xt3ixk2je7Li4QncOTaGRVvTOJ5byNtzRxLbvdpvMGokpGzGw2Ja3F4yoAv/WHqQU2cccgbOHIcTOzmeU8jeE2dqhCm7uSnmXhjN9pQcth2rmrTYLGht/GDHNprEwR//Bd8/ZkqKZNdMrly7bQ/T3NZzpv8NtTfzaiZEQAjnhl1A+IW6zFHmcgZcCT0vaJ5jxVxk+m7bS0vY2fKOSWqb/HSTTQIX9g7hXzcN59YLoysHe9r9EJXhnI4Z1Uez8nnxh4NMGdiFST89C1mHYM5CuGZ+pcbnG2xCkFM20dnPkz/NHMzutDNc9fJaikrL+ces+Mo6P3WV2bDj36UiY94zyzifvzzRue4+HYOvhZF3wY+vVBbxK8yBpB8o6j+d9zccY9qQ7vQKq2wHG+jjwWPTYln+mwn89xfjKirbViFylMlxOXMcNzfFH6fFUlquee5bBz/Ronvg35ewc73JxZ0UG17jMNclRBHg5X7OWkRxWTUHe3kZfHIzvBgHC6bAp3Phu0dh43xTAPL1i2Dbh1UDHza/iYcqJ+TSB89pLg1BBIRwbtgrujYkgul8IPoi835kdeVYYY7J94i+CPpf3uRDK6W4Iq4bgT4OAiasv/nuk36oGOob7o+nuxu7UnP5v8W7cXdz4/l++8zT6cTfO59D1CjzBG+1MnVwN64c0o3s/BIeuzKW3vabct5Jk6xWX1KbPZs6/1SFoNxXHsFnW5z4GBy57M+mH/fi+yH7iBEU1lIWlYwhv6Scn0/s7XS3HiG+9OkS4PyYdu0o1eTcRof6cce4GD7fmsr2lByjPSSvBWsZYxIfYlRwYeX1Ol6SlzvXJ0Tx9a4TDe/xUY2CkjIu+dsqfvnxNmP+0xq+fthkiI/7Ndz0Gdy3Dh45Ao+lwwOJ5vv48memrEhBNoX5Z7nw9Jcc7HQhylYC35WIgBDODXcv08egtk5y5xuBERDcu6qjes3fTbb5lD81v5alFAydDXu/NH2yMW1cB3YNYOHmFNYmZfL0xb4ErXjU+CvGPuT8OD3GmCJ7WSYX4rlrh7BgbgI3OXbuS1pm3utzrjv2pk7fC0E9GBQTycJNKRV+Eae4e8EN74LC3BB3LsQa2JNnd/owJTacAV2bYMLsOgQsXqa+l40HLulDWIAXTyzZg3X3YkBTeM07uJcX8iJ/M9V1nTD3wmjKtebFHw46XV8fn28xZeCX7DjOc9/th7UvwJa3jU9q0uPQdzJ0HWweupQykXe3LYFJT8D+r+G1sWR8/muCVR5lo+5v0hwaiwgI4dyxOQMFGzEXG8dxeZnpOLfxdYi/EbrHu+Z8k5+CIbNg+Z8qhMSgiEDOFpeREBXAzMNPGkf81W9U9JuogT3RKmUjYJ6YLxkQXjW7+9D3pp5W17i65+NYjyl9D4QPZs6oHhzLLuDHw1l179s5Gma+Did2wJHVbO80gTNF5TxwSROflt09zfeeurliyN/Lnd9NHcD2lBxOb/4EusaxUo3mV6U/o3vBPvjqQae5LD1CfLnn4l4s3JzC5/VpQ9WwWjVv2ZISbxnTk/Q178Gyp0weyCV/rH1HN4sRIHf9AJ5+9Dj8CfvpSf8xVzTq/E1FBIRw7sxZaJ5yBEPMxVCSZ25yPzxhqphe8pjrzudmMZFIDkLigl4h+HhYeKPnclTaZrjqHzVzQRwJ6WMi0o5tdL6+vNSU5+47uX4tyK5B5KSYfI/wQUwd3JVAH48qCWel5VbWJ2XyxJI9PP3fvaRkF5gVA66AsQ+ilYXn0uIY3y+MIZFBDf8+qhM5Eo5vh7LKbOhrhkUwuXsRIad3UDzgapbuS2ez9wWUj38Udn4CP77q9FC/ndKfC3qF8PvFu2pkktfFD/vSSc4q4O6LYnhicAZ/85zPemssKwc83qBk0b304rchL/NC2fUsjZmHh3sD6mY1Ay4r1iecR4Q4tw2ft9j9EGv+Bge+hvHzjJblSuxCAmD5n7jqEphyx1i83vsnDJ1TWfeoNpQyWkRKLQIiZRMU50K/y+qfi2+ISX5LXmMy2rvE4u1h4ephEXy08RiLt6Wy5mAmy/afIrewFC93N6xa8876ZK4a0o37J/Sh/6QnWeh2JRuXZvJZU7UHO5EjjfP75M6Knt9ubooneh2AbHgrJ54V+08xsX8XLOMfgVO7YekfoMtA6HNplUO5W9x4ac4wpr28hvs+2MJXD4wj0Lf+oIM31x4hIsiHqaFZWN69FWtoH14s+yO7P9nDf+7txOCIms2XtNb8+FMWr68+zOqDGfh5Wpgz5tdN16aagAgIQWhu/MNMWYkDXxuTzNhftsx5qwkJL69OJiT18ucbtn/UKNNfOz+rpk/p0HcmlDlmvPN9q8/DLwyO2PwwthpMc0b14J31yfzqkx0E+XowaWA4UwaFc1HfUHILS3lrzRE+2nSML7YfZ9LALuxKy+OCXiHOo5Mag91RnbKpQkAARKR+TbJPLM9vME7nSQPDzdP8zNdNyflP55qKszEXQ/TFFd9JWIAX/7ppBLPn/8iv/7Odf9+agJtb7VrVztQcNh3J5vmJfrh/fD14+uF2y+e8rEKZ+eo67nx3M/+59wLKrJqjWfkkZxZwNCufxKOn2XP8DKH+Xvz2sv7cPLpng4RRcyICQhBcQfRFcGovXPrHplembQoVQkKZHIKbPgPvBjp3e4wx76mbakY6HVpqQoEbeix/W7KcxQuCTZJc/64BvHHLCAJ9PEjo2dkk+9nw9XTnsWmx/HxiH9778SjvrD/C6YJS/nFDfMPOVxd2H1nqJuBnZizzEJzcRciEp/BdbqG03MrF/WyReF7+MOdj+GYe7PyPyfIGCI8zwuLCXzCiZzceuzKWx5fs4V8rk3jgkr61nv7NNUcY6JXFdbsfNn0t5v4XAiMJB96+fSTXvfYj4/+6sso+AV7u9Oriz5+vjuOa4RENK8XuAkRACIIrGH2vyTMYOrvlz+1mgatfh6l/qQxDbgjdhxl/ScrGqgIiJ8UIuyl/avix/MOBXdBlQJUSJvW1xuzs58mDk/py98UxJJ06e26+B0dsCXMV7F4EKAKGX89fgjTHc4oI8HZ4Ou8cDTcuNL6X49tNdvyR1abdacZ+uGURt17Qk63HTvP3pQcZEhnExf1qJgMezylk+66dfOX/Z9zKiuG2r6o0wRrQtRMf3z2G5ftPERXsQ88QP6JDfAn283Ra/r2lEQEhCK4gpLcpmd5aKNU44QCmyU63oVVCQgFIWmre+05p+LHskUxdGtER0AFfT/fmEw5gEub2LDZ5DwHdYPdnJuy3U3dmxNexn8XDCJeokXDxw6Z3yQ+PQ8pmVNRI/nJNHPtP5HHv+1v48zWDuXpY1Wi+RSt+5EOPpwlQJXDrV04jwOIiA4mLrOmDaAtIFJMgCJVEjYG0LVUifji01CTH2ftJNwQ/29N0Y1rGuhLHhLn0PSarffA1jT/OyLuME37Vs4ARZO/fOYq4yEB+9ckOHl20s6IceX7GUWZuv5cQSwFut31phG87QwSEIAiVRI0yLWBP7jLLZcWmdWffyxqX5GfXINqKgHBMmNv9uckLaUqZbC9/uPAXJnM9NRGALp28+eiu0fxsQm8+3pTC1f9az9Hkw5QvuJJO5JEy7WNjvmuHiIAQBKGSioS5DeY9ea1pJ9sY8xIYh3fXOIgY3rzzayqOCXO7P4deE5pefXjk3SZnZOWzlYe3uPHI1AG8PXckGTl5nHr7RjwL03k25Bn6D29A5FcbxaUCQik1VSl1QCmVpJSa52T9r5VSe5VSO5VSy5RSPR3WlSulttteS1w5T0EQbHTqZsxJ9nyIQ0tNH3F7c6KGEjEc7lsL3m3Ith450lxXztGmmZfsVGgRSyF1S5VVEwd0YeWwVYxU+/hdyV2Mv/TKc5x06+IyAaGUsgCvApcDscAcpVT1noPbgASt9RDgM8AxYLtQax1ve0131TwFQahG1GhjitHalNeIvgg8fVt7VudO5Ejz7uYBA6ad27FG3W1Kba96tur4ni/w3/o65Ql3cfv9v6s3aqut40oNYhSQpLU+rLUuARYCVYx+WusVWmtbfj0bACnoIwitTdRoyDthfA/ZPzXevNRWsTuq+04Gn6BzO5ZXgNEiDn1vnPoAGQfhy59D5EgsU/9CfNQ5nqMN4EoBEQGkOCyn2sZq407gG4dlb6VUolJqg1JqpgvmJwiCM+x+iOW2vIe+k1tvLs1Jp+5wyR9gQg1rd9MYdY/RIlY+B8VnTV8Hd2+4/l3j8+gAtIk8CKXUzUAC4OjN6am1TlNK9QKWK6V2aa1/crLvPcA9AD161FOnXhCE+gkfZEq4pyWa0NbgmNaeUfNx8cPNdyyvALjg50aQfnCtKZV+yxdVWrK2d1ypQaQBjuUjI21jVVBKTQL+D5iutS62j2ut02zvh4GVgNM4Ma31fK11gtY6ISysjraGgiA0DDdLZc2ijmJechWj7gXvIBP1dckfoFf7jVhyhisFxGagr1IqRinlCcwGqkQjKaWGAW9ghMMph/HOSikv2+dQYCyw14VzFQTBEbuZqaOYl1yFdye46kXTiGncr1p7Ns2Oy0xMWusypdQDwHeABVigtd6jlHoKSNRaLwH+CvgDn9rqjhyzRSwNBN5QSlkxQuxZrbUICEFoKYbdbBLmeo5t7Zm0fQZdbV4dEKWddE5qryQkJOjExMTWnoYgCEK7QSm1RWud4GydZFILgiAIThEBIQiCIDhFBIQgCILgFBEQgiAIglNEQAiCIAhOEQEhCIIgOEUEhCAIguAUERCCIAiCUzpUopxSKgM42sTdQ4HMZpxOW6AjXhN0zOuSa2o/dLTr6qm1dlrIrkMJiHNBKZVYWzZhe6UjXhN0zOuSa2o/dNTrcoaYmARBEASniIAQBEEQnCICopL5rT0BF9ARrwk65nXJNbUfOup11UB8EIIgCIJTRIMQBEEQnHLeCwil1FSl1AGlVJJSqpm6mbc8SqkFSqlTSqndDmPBSqmlSqlDtvfOrTnHxqKUilJKrVBK7VVK7VFKPWgbb7fXpZTyVkptUkrtsF3Tk7bxGKXURtvv8BNbF8Z2h1LKopTappT6r225XV+XUipZKbVLKbVdKZVoG2u3v7/Gcl4LCKWUBXgVuByIBeYopWJbd1ZN5h1garWxecAyrXVfYJltuT1RBvxGax0LjAF+bvv7tOfrKgYu0VoPBeKBqUqpMcBzwD+01n2A08CdrTfFc+JBYJ/Dcke4rola63iH0Nb2/PtrFOe1gABGAUla68Na6xJgITCjlefUJLTWq4HsasMzgHdtn98FZrbknM4VrfUJrfVW2+c8zI0ngnZ8Xdpw1rboYXtp4BLgM9t4u7omO0qpSOBK4E3bsqIDXJcT2u3vr7Gc7wIiAkhxWE61jXUUwrXWJ2yfTwLhrTmZc0EpFQ0MAzbSzq/LZobZDpwClgI/ATla6zLbJu31d/gi8AhgtS2H0P6vSwPfK6W2KKXusY21699fY3Bv7QkILYPWWiul2mXImlLKH/gceEhrfcY8mBra43VprcuBeKVUELAYGNC6Mzp3lFLTgFNa6y1KqQmtPJ3mZJzWOk0p1QVYqpTa77iyPf7+GsP5rkGkAVEOy5G2sY5CulKqG4Dt/VQrz6fRKKU8MMLhQ631Ittwu78uAK11DrACuAAIUkrZH9ja4+9wLDBdKZWMMdVeAvyTdn5dWus02/spjDAfRQf5/TWE811AbAb62iItPIHZwJJWnlNzsgS4zfb5NuDLVpxLo7HZsN8C9mmtX3BY1W6vSykVZtMcUEr5AJMxvpUVwHW2zdrVNQForR/VWkdqraMx/0fLtdY30Y6vSynlp5QKsH8GpgC7ace/v8Zy3ifKKaWuwNhOLcACrfUzrTujpqGU+hiYgKk0mQ48DnwB/Afogalye4PWuroju82ilBoHrAF2UWnX/j3GD9Eur0spNQTj2LRgHtD+o7V+SinVC/PkHQxsA27WWhe33kybjs3E9LDWelp7vi7b3BfbFt2Bj7TWzyilQminv7/Gct4LCEEQBME557uJSRAEQagFERCCIAiCU0RACIIgCE4RASEIgiA4RQSEIAiC4BQREILQCJRS5bbKnvZXsxVqU0pFO1bjFYTWRkptCELjKNRax7f2JAShJRANQhCaAVvfgOdtvQM2KaX62MajlVLLlVI7lVLLlFI9bOPhSqnFtr4QO5RSF9oOZVFK/dvWK+J7W7a1ILQKIiAEoXH4VDMxzXJYl6u1jgNewWTnA7wMvKu1HgJ8CLxkG38JWGXrCzEc2GMb7wu8qrUeBOQA17r0agShDiSTWhAagVLqrNba38l4MqYR0GFbgcGTWusQpVQm0E1rXWobP6G1DlVKZQCRjmUnbCXNl9oa0aCU+h3gobX+UwtcmiDUQDQIQWg+dC2fG4NjnaJyxE8otCIiIASh+Zjl8P6j7fN6THVTgJswxQfBtKq8HyoaCAW21CQFoaHI04kgNA4fWzc4O99qre2hrp2VUjsxWsAc29gvgLeVUr8FMoDbbeMPAvOVUndiNIX7gRMIQhtCfBCC0AzYfBAJWuvM1p6LIDQXYmISBEEQnCIahCAIguAU0SAEQRAEp4iAEARBEJwiAkIQBEFwiggIQRAEwSkiIARBEASniIAQBEEQnPL/Ymoo6+jLwFsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparation of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grid</th>\n",
       "      <th>Best score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extra Tree</td>\n",
       "      <td>-0.010199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>-0.038432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>-0.039871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>-0.047538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-0.072469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGB wrapped</td>\n",
       "      <td>-0.080796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LGBM wrapped</td>\n",
       "      <td>-0.094547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NN</td>\n",
       "      <td>-0.223488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting wrapped</td>\n",
       "      <td>-1.328357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>-5.731186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>-5.741624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Grid  Best score\n",
       "3                  Extra Tree   -0.010199\n",
       "4               Decision Tree   -0.038432\n",
       "1                  KNeighbors   -0.039871\n",
       "5               Random Forest   -0.047538\n",
       "10                   CatBoost   -0.072469\n",
       "6                 XGB wrapped   -0.080796\n",
       "9                LGBM wrapped   -0.094547\n",
       "11                         NN   -0.223488\n",
       "2   Gradient Boosting wrapped   -1.328357\n",
       "7                       Ridge   -5.731186\n",
       "0           Linear Regression   -5.741624"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models = best_grids.copy()\n",
    "best_models.loc[len(best_models.index)] = ['NN', -df_hist['val_mae'].min()]\n",
    "best_models = best_models.sort_values(by=\"Best score\", ascending=False)\n",
    "best_models.head(len(best_grids.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models.to_excel(ROOT_PATH + '\\\\data\\\\metrics\\\\models_score.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "extratree = Pipeline([\n",
    "                (\"extratree\",ExtraTreesRegressor())\n",
    "               ])\n",
    "\n",
    "neighbors = Pipeline([\n",
    "                (\"neighbors\",KNeighborsRegressor())\n",
    "               ])\n",
    "\n",
    "\n",
    "decisionTree = Pipeline([\n",
    "                    (\"decisionTree\",DecisionTreeRegressor())\n",
    "                   ])\n",
    "\n",
    "# Extra Tree\n",
    "grid_extraTree = {\"extratree__max_depth\":list(range(1,10)) # Profundidades del árbol. Cuanto más profundo, mas posibilidades de overfitting,\n",
    "                                            # pero  mas preciso en entrenamiento.\n",
    "              }\n",
    "\n",
    "# KNN\n",
    "grid_neighbors = {\"neighbors__n_neighbors\": [3,5,7,9,11],       # Pares acepta sklearn, pero se suele poner impares, por los empates\n",
    "                  \"neighbors__weights\": [\"uniform\",\"distance\"]  # Ponderar o no las clasificaciones en \n",
    "                                                     # función de la inversa de la distancia a cada vecino\n",
    "                  }\n",
    "\n",
    "# ARBOL DE DECISION\n",
    "grid_decisionTree = {\"decisionTree__max_depth\":list(range(1,10)) # Profundidades del árbol. Cuanto más profundo, mas posibilidades de overfitting,\n",
    "                                            # pero  mas preciso en entrenamiento.\n",
    "              }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    }
   ],
   "source": [
    "# Almaceno en una lista de tuplas los modelos (nombre que le pongo, el modelo, hiperparametros)\n",
    "models = [('Extra Trees Regressor', extratree, grid_extraTree),\n",
    "            ('KNeighbors Regressor', neighbors, grid_neighbors),\n",
    "            ('Decision Tree Regressor', decisionTree, grid_decisionTree),\n",
    "         ]\n",
    "\n",
    "# Declaro en un diccionario los pipelines e hiperparametros\n",
    "models_gridsearch = {}\n",
    "\n",
    "for m in models:\n",
    "    models_gridsearch[m[0]] = GridSearchCV(m[1],\n",
    "                                          m[2],\n",
    "                                          cv=5,\n",
    "                                          scoring=\"neg_mean_squared_error\",\n",
    "                                          verbose=1,\n",
    "                                          n_jobs=-1)\n",
    "    \n",
    "    models_gridsearch[m[0]].fit(X_train, y_train)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grid</th>\n",
       "      <th>Best score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighbors Regressor</td>\n",
       "      <td>-0.001288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Extra Trees Regressor</td>\n",
       "      <td>-0.159141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree Regressor</td>\n",
       "      <td>-0.254597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Grid  Best score\n",
       "1     KNeighbors Regressor   -0.001288\n",
       "0    Extra Trees Regressor   -0.159141\n",
       "2  Decision Tree Regressor   -0.254597"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_grids = [(i, j.best_score_) for i, j in models_gridsearch.items()]\n",
    "\n",
    "best_grids = pd.DataFrame(best_grids, columns=[\"Grid\", \"Best score\"]).sort_values(by=\"Best score\", ascending=False)\n",
    "best_grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('neighbors',\n",
       "                 KNeighborsRegressor(n_neighbors=3, weights='distance'))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El mejor ha sido KNN\n",
    "models_gridsearch['KNeighbors Regressor'].best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20.4  4.8]\n",
      " [15.6  6. ]\n",
      " [31.2 29.4]\n",
      " ...\n",
      " [ 6.6  6. ]\n",
      " [27.6  6. ]\n",
      " [36.  17.4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\src\\theBridge\\course-env\\lib\\site-packages\\sklearn\\base.py:442: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = KNeighborsRegressor(n_neighbors=3, weights='distance')\n",
    "# model = DecisionTreeRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real point          x    y\n",
      "6520  19.8  7.8\n",
      "Point predicted [[19.8  7.8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\src\\theBridge\\course-env\\lib\\site-packages\\sklearn\\base.py:442: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "i = 150\n",
    "# test = X_test.iloc[i:i+1, :]\n",
    "print(f'Real point {y_test.iloc[i:i+1, :]}')\n",
    "print(f'Point predicted {model.predict(X_test.iloc[i:i+1:, :])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\src\\theBridge\\course-env\\lib\\site-packages\\sklearn\\base.py:442: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.0000004 \n",
      "RMSE: 0.00064 \n",
      "MAE:  0.00002 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(\"MSE:  %.7f \" % mean_squared_error(y_test, predictions))\n",
    "print(\"RMSE: %.5f \" % np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print(\"MAE:  %.5f \" % mean_absolute_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(ROOT_PATH + '\\\\model\\selected_models\\\\KNeighborsRegressor_nb.model', \"wb\") as archivo_salida:\n",
    "    pickle.dump(model, archivo_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor(n_neighbors=3, weights='distance')\n"
     ]
    }
   ],
   "source": [
    "# Para volver a leer el modelo\n",
    "with open(ROOT_PATH + '\\\\model\\selected_models\\\\KNeighborsRegressor_nb.model', \"rb\") as archivo_entrada:\n",
    "    import_model = pickle.load(archivo_entrada)\n",
    "    \n",
    "print(import_model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9fe7e7741b3f19bcd135589f0a4246388c4ceff90e79f616981a3065da97231"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('course-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
